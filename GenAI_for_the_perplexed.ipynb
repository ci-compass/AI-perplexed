{
 "cells": [
  {
   "cell_type": "raw",
   "id": "49a58314",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"A guide to Generative AI for the Perplexed\"\n",
    "date: 2025-10-29\n",
    "author:\n",
    "  - name: Charles F. Vardeman II\n",
    "    id: cfv\n",
    "    orcid: 0000-0002-1825-0097\n",
    "    email: cvardema@nd.edu\n",
    "    affiliation:\n",
    "      - name: Center for Research Computing, University of Notre Dame\n",
    "        city: Notre Dame\n",
    "        state: IN\n",
    "        url: https://crc.nd.edu\n",
    "      - name: CI-Compass\n",
    "        url: https://ci-compass.org\n",
    "keywords:\n",
    "  - Generative AI in Science\n",
    "  - Science Agents\n",
    "license: \"CC BY\"\n",
    "citation:\n",
    "  type: document\n",
    "  container-title: Zenodo\n",
    "  doi: 10.5281/zenodo.10815117\n",
    "links:\n",
    "  - text: \"Video Presentation\"\n",
    "    url: \"https://youtube.com/...\"\n",
    "  - text: \"GitHub Repository\"\n",
    "    url: \"https://github.com/ci-compass/AI-perplexed\"\n",
    "funding: \"This project is supported by the U.S. National Science Foundation Office of Advanced Cyberinfrastructure in the Directorate for Computer Information Science under Grant #2127548\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    code-fold: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49926eb8",
   "metadata": {},
   "source": [
    "## GitHub CI-compass Organization\n",
    "- [GitHub Link: https://github.com/ci-compass/AI-perplexed](https://github.com/ci-compass/AI-perplexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984505e3",
   "metadata": {},
   "source": [
    "# A guide to Generative AI for the Perplexed\n",
    "\n",
    "> This video is meant to be a rough guide to some of the concepts and to help understand generative AI and preparation for the NSF CyberInfrastructure Center of Excellence [CI-Compass](https://ci-compass.org/) [Virtual Workshop - AI Meets CI: Intelligent Infrastructure for Major & Midscale Facilities](https://ci-compass.org/news-and-events/events/virtual-workshop-ai-meets-ci-intelligent-infrastructure-for-major-and-midscale-facilities/). The purpose is to start from the beginning and try to de-mystify **chatbot** based Generative AI.\n",
    "\n",
    "![](https://ci-compass.org/assets/629872/300x/ai_meets_ci_recreation_1.png)\n",
    "\n",
    "## Chat based generative AI\n",
    "\n",
    "### Chat interface\n",
    "- [OpenAI ChatGPT](https://chatgpt.com/)\n",
    "- [Anthropic Claude](https://claude.ai/new)\n",
    "- [Google Gemini](https://gemini.google.com/)\n",
    "\n",
    "### Terminal Based Coding Agents\n",
    "- [Anthropic Claude Code Cli](https://www.claude.com/product/claude-code)\n",
    "- [OpenAI Codex Cli](https://github.com/openai/codex)\n",
    "- [Google Gemini Cli](https://geminicli.com/)\n",
    "- [Microsoft Visual Studio Code](https://code.visualstudio.com/)\n",
    "\n",
    "### Notebook Based AI\n",
    "- [AnswerAI SolveIT](https://solve.it.com)\n",
    "- [Google Collab](https://developers.googleblog.com/en/data-science-agent-in-colab-with-gemini/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef43300",
   "metadata": {},
   "source": [
    "## Andrej Karpathy \"Deep Dive into LLMs like ChatGPT\"\n",
    "![](./images/karpathy-yt.png)\n",
    "\n",
    "- [Deep Dive into LLMs like ChatGPT: https://youtu.be/7xTGNNLPyMI](https://youtu.be/7xTGNNLPyMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1191d",
   "metadata": {},
   "source": [
    "## Andrej Karpathy - How I use LLMs\"\n",
    "![](./images/karpathy-yt-use.png)\n",
    "\n",
    "- [How I use LLMs YT link: https://youtu.be/EWvNQjAaOHw](https://youtu.be/EWvNQjAaOHw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf28ba6",
   "metadata": {},
   "source": [
    "## \"Foundation Models\"\n",
    "\n",
    "- [What is are Foundation Models? https://aws.amazon.com/what-is/foundation-models/](https://aws.amazon.com/what-is/foundation-models/)\n",
    "\n",
    "<hr>\n",
    "\n",
    "- **Multimodal \"Text\" models:** GPT-5; Anthropic Claude Opus, Sonnet; Google Gemini 2.5; Meta LAMMA, Deepseek R1\n",
    "- **Image or Video Generation from text:** OpenAI Sora, [Google Imagen](https://imagen.research.google/)\n",
    "- **Science Foundation Models:** [Futurehouse ether0](https://www.futurehouse.org/research-announcements/ether0-a-scientific-reasoning-model-for-chemistry)\n",
    "    - [M. Hu et al., ‚ÄúA survey of scientific Large Language Models: From data foundations to agent frontiers,‚Äù arXiv [cs.CL], 28-Aug-2025. https://arxiv.org/abs/2508.21148](https://arxiv.org/abs/2508.21148)\n",
    "    - [Towards a Physics Foundation Model https://arxiv.org/html/2509.13805v2](https://arxiv.org/html/2509.13805v2)\n",
    "    - [H. Cui et al., ‚ÄúTowards multimodal foundation models in molecular cell biology,‚Äù Nature, vol. 640, no. 8059, pp. 623‚Äì633, Apr. 2025.https://www.nature.com/articles/s41586-025-08710-y](https://www.nature.com/articles/s41586-025-08710-y)\n",
    "    - [Nurips 2024: Foundation Models for Science: Progress, Opportunities, and Challenges](https://neurips.cc/virtual/2024/workshop/84714)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb5a18b",
   "metadata": {},
   "source": [
    "### \"Groking\" -- Memorization vs Generalization\n",
    "> \"Out of Distribution Phenomenon\" where  model initially overfits to the training set, and then suddenly generalizes to unseen test samples after continuous training\n",
    "\n",
    "![An interactive introduction to grokking and mechanistic interpretability](https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XpCnhaAQrssq8tJBG/rfpm8jhcd5kog1mqi8jn)\n",
    "\n",
    "- [An interactive introduction to grokking and mechanistic interpretability](https://www.alignmentforum.org/posts/XpCnhaAQrssq8tJBG/an-interactive-introduction-to-grokking-and-mechanistic)\n",
    "- [Do Machine Learning Models Memorize or Generalize? https://pair.withgoogle.com/explorables/grokking/](https://pair.withgoogle.com/explorables/grokking/)\n",
    "- [Anthropic Transformer Circuits](https://transformer-circuits.pub/)\n",
    "- [Y. Tian, ‚ÄúProvable scaling laws of feature emergence from learning dynamics of grokking,‚Äù arXiv [cs.LG], 30-Sept-2025.https://arxiv.org/html/2509.21519v3](https://arxiv.org/html/2509.21519v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f9ec9",
   "metadata": {},
   "source": [
    "## \"Context Window -- Trained Model\"\n",
    "Think of an LLM as a kind of supercharged text predictor: you give it a sequence of tokens (words or subwords) and it predicts the next token, then the next, etc. What we call the context window is simply how many tokens the model can look back at when making each prediction.\n",
    "\n",
    "- If a model has a context window of, say, 4,096 tokens, then when it‚Äôs about to predict token N, it only ‚Äúknows‚Äù about tokens N-4,095 through N-1 (plus whatever internal state) ‚Äî it cannot directly ‚Äúsee‚Äù tokens older than that.\n",
    "\n",
    "- Everything the model uses to ground its prediction must be inside that window ‚Äî the user prompt, the system instructions, examples, retrieved documents, conversation history, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be634c62",
   "metadata": {},
   "source": [
    "### Why does the Context Window Matter?\n",
    "1. **Scope of what the model knows in this invocation -- Stateless Model**\n",
    "> Because the model cannot remember everything ever said, only what fits into its window ‚Äî if you want it to reference a piece of text, you must include it (or a compressed version of it) in the window.\n",
    "\n",
    "2. **Management of context = performance trade-offs**\n",
    "> The more tokens you feed (longer history, more retrieved docs, more examples), the richer the information the model has ‚Äî but you are limited by the window size. If you exceed it, older tokens get truncated (lost). If you fill it with irrelevant stuff, you can confuse the model (context noise) rather than help it. Karpathy calls this ‚Äúthe delicate art and science of filling the context window with just the right information for the next step.‚Äù\n",
    "\n",
    "3. **Analogy: human coworker with short-term memory**\n",
    "> Karpathy uses an analogy: the LLM is like a coworker who has anterograde amnesia ‚Äî they forget everything beyond a short timeframe. So if you want them to reference something older, you must remind them (i.e., re-include it in the window)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98a0c2",
   "metadata": {},
   "source": [
    "### Multimodal Context Window\n",
    ">Now imagine we extend that idea: Instead of feeding the model just text tokens, we also feed in image tokens, audio tokens, video frame tokens, sensor tokens, etc. \n",
    "\n",
    "**Each modality has its own tokenizer:**\n",
    "\n",
    "- Text ‚Üí word/subword tokens\n",
    "\n",
    "- Images ‚Üí small patch tokens (like 16√ó16 pixels each)\n",
    "\n",
    "- Audio ‚Üí waveform chunks or spectrogram tokens\n",
    "\n",
    "All of those get projected into the same vector space and concatenated into one long sequence.\n",
    "That sequence is the multimodal context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670dfc0",
   "metadata": {
    "time_run": "5:42:30p"
   },
   "outputs": [],
   "source": [
    "from dialoghelper import *\n",
    "fc_tool_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b328965",
   "metadata": {},
   "source": [
    "Tools available from `fastcore.tools`:\n",
    "\n",
    "- &`rg`: Run the `rg` command with the args in `argstr` (no need to backslash escape)\n",
    "- &`sed`: Run the `sed` command with the args in `argstr` (e.g for reading a section of a file)\n",
    "- &`view`: View directory or file contents with optional line range and numbers\n",
    "- &`create`: Creates a new file with the given content at the specified path\n",
    "- &`insert`: Insert new_str at specified line number\n",
    "- &`str_replace`: Replace first occurrence of old_str with new_str in file\n",
    "- &`strs_replace`: Replace for each str pair in old_strs,new_strs\n",
    "- &`replace_lines`: Replace lines in file using start and end line-numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd1f3e",
   "metadata": {
    "time_run": "5:42:30p"
   },
   "outputs": [],
   "source": [
    "from fastcore.tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dfc81e",
   "metadata": {},
   "source": [
    "Tools available from `fastcore.tools`:\n",
    "\n",
    "- &`rg`: Run the `rg` command with the args in `argstr` (no need to backslash escape)\n",
    "- &`sed`: Run the `sed` command with the args in `argstr` (e.g for reading a section of a file)\n",
    "- &`view`: View directory or file contents with optional line range and numbers\n",
    "- &`create`: Creates a new file with the given content at the specified path\n",
    "- &`insert`: Insert new_str at specified line number\n",
    "- &`str_replace`: Replace first occurrence of old_str with new_str in file\n",
    "- &`strs_replace`: Replace for each str pair in old_strs,new_strs\n",
    "- &`replace_lines`: Replace lines in file using start and end line-numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec67704",
   "metadata": {
    "time_run": "5:42:30p"
   },
   "outputs": [],
   "source": [
    "tool_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2dd6f",
   "metadata": {},
   "source": [
    "Tools available from `dialoghelper`:\n",
    "\n",
    "- &`curr_dialog`: Get the current dialog info.\n",
    "- &`msg_idx`: Get absolute index of message in dialog.\n",
    "- &`add_html`: Send HTML to the browser to be swapped into the DOM using hx-swap-oob.\n",
    "- &`find_msg_id`: Get the current message id.\n",
    "- &`find_msgs`: Find messages in current specific dialog that contain the given information.\n",
    "  - (solveit can often get this id directly from its context, and will not need to use this if the required information is already available to it.)\n",
    "- &`read_msg`: Get the message indexed in the current dialog.\n",
    "  - To get the exact message use `n=0` and `relative=True` together with `msgid`.\n",
    "  - To get a relative message use `n` (relative position index).\n",
    "  - To get the nth message use `n` with `relative=False`, e.g `n=0` first message, `n=-1` last message.\n",
    "- &`del_msg`: Delete a message from the dialog.\n",
    "- &`add_msg`: Add/update a message to the queue to show after code execution completes.\n",
    "- &`update_msg`: Update an existing message.\n",
    "- &`url2note`: Read URL as markdown, and add a note below current message with the result\n",
    "- &`msg_insert_line`: Insert text at a specific location in a message.\n",
    "- &`msg_str_replace`: Find and replace text in a message.\n",
    "- &`msg_strs_replace`: Find and replace multiple strings in a message.\n",
    "- &`msg_replace_lines`: Replace a range of lines in a message with new content.\n",
    "  - Always first use `read_msg( msgid=msgid, n=0, relative=True, nums=True)` to view the content with line numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff4bef",
   "metadata": {},
   "source": [
    "### \"Thinking Models and Chain of Thought\" (Deepseek-R1 from Karpathy Video)\n",
    "![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVgTjwA0IzKekrQoMziCmDXjO10QKjdDdzK1Oj8bZToPOI6VjVzTKXZ6vnWvAGOdVnWznJK2ZZjfBuTLojobayI_yrvlFzE3dCErF2j5wKLGFWAkuGP9-r-hMrqFivnjYhbCIu7HFINSmHu4wUjlKHfJxWHZ8Y7CYUowWvxTeRJhQEAUswGh2fUd3VHA/s2500/chainofthought.png)\n",
    "\n",
    "- [Language Models Perform Reasoning via Chain of Thought (May 2022)https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/](https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c7145b",
   "metadata": {},
   "source": [
    "## ReACT\n",
    "![](https://react-lm.github.io/files/diagram.png)\n",
    "\n",
    "- [ReAct: Synergizing Reasoning and Acting in Language Models Blog: https://react-lm.github.io/](https://react-lm.github.io/)\n",
    "- [S. Yao et al., ‚ÄúReAct: Synergizing reasoning and acting in language models,‚Äù Int Conf Learn Represent, vol. abs/2210.03629, Oct. 2022. https://openreview.net/forum?id=WE_vluYUL-X](https://openreview.net/forum?id=WE_vluYUL-X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e98f0",
   "metadata": {},
   "source": [
    "## Tool Use\n",
    "> Tool use is when a language model learns or is prompted to call external functions ‚Äî like calculators, search engines, databases, or other APIs ‚Äî to augment its own capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368aaf3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "So I would like to demonstrate tool use within the Solvit notebook, which is meant to be sort of this presentation walkthrough of LLM based topics. So I'd like to use essentially a simple definition or a simple Python function, and then use fast query-tills to explain how you can get essentially cast the function to something the LLM understands in terms of JSON. And then lastly, sort of demonstrate how you can then use the tool within your context.\n",
    "\n",
    "##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great idea! Let's build this demonstration step by step. We'll create a simple Python function, show how to make it \"LLM-readable\" using JSON schema, and then demonstrate tool use in action.\n",
    "\n",
    "Let's start with a simple example function. What kind of function would you like to use for the demonstration? Some options:\n",
    "\n",
    "1. A calculator function (e.g., compound interest, unit conversion)\n",
    "2. A data lookup function (e.g., get information about something)\n",
    "3. A text processing function (e.g., count words, analyze sentiment)\n",
    "4. Something domain-specific for your audience (CI/research computing related?)\n",
    "\n",
    "What would work best for your presentation context?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39965fbf",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Yeah, I think something domain specific might be kind of good. So I have RD-Kit installed. Could we walk through step by step in the solvit sort of way of how to create a function for RD-Kit?\n",
    "\n",
    "##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! RDKit is great for this - it's domain-specific and will resonate with your research computing audience.\n",
    "\n",
    "Let's start simple. What kind of molecular operation would you like to demonstrate? Here are some straightforward options:\n",
    "\n",
    "1. Calculate molecular weight from a SMILES string\n",
    "2. Count the number of atoms in a molecule\n",
    "3. Check if a SMILES string is valid\n",
    "4. Calculate LogP (lipophilicity)\n",
    "\n",
    "Which one sounds good, or do you have another RDKit function in mind?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b8dfc3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Let's calculate molecular weight. Go ahead and write the function. After we write the function, we will want to use fastcore to illustrate \"what the function looks like\" to solveit.\n",
    "\n",
    "##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Here's a simple function to calculate molecular weight from a SMILES string:\n",
    "\n",
    "```python\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "def get_molecular_weight(smiles: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the molecular weight of a molecule from its SMILES string.\n",
    "    \n",
    "    Args:\n",
    "        smiles: A SMILES string representing the molecule\n",
    "        \n",
    "    Returns:\n",
    "        The molecular weight in g/mol, or None if the SMILES is invalid\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    return Descriptors.MolWt(mol)\n",
    "```\n",
    "\n",
    "Go ahead and run this to define the function. Once you've done that, let me know and we'll use fastcore to show what this function looks like to an LLM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad31b9a",
   "metadata": {
    "time_run": "5:42:30p"
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "def get_molecular_weight(smiles: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the molecular weight of a molecule from its SMILES string.\n",
    "    \n",
    "    Args:\n",
    "        smiles: A SMILES string representing the molecule\n",
    "        \n",
    "    Returns:\n",
    "        The molecular weight in g/mol, or None if the SMILES is invalid\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    return Descriptors.MolWt(mol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c380990",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "OK. How do I demonstrate what this function looks like to solveit?\n",
    "\n",
    "##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "To show what this function looks like to an LLM, you can use fastcore's tooling. Try running:\n",
    "\n",
    "```python\n",
    "from fastcore.meta import delegates\n",
    "import inspect\n",
    "\n",
    "# Show the JSON schema that describes the function\n",
    "print(get_molecular_weight.__name__)\n",
    "print(inspect.signature(get_molecular_weight))\n",
    "print(get_molecular_weight.__doc__)\n",
    "```\n",
    "\n",
    "This will show you the basic elements. But to see the actual JSON schema format that gets sent to an LLM, you'll want to use the schema generation. Do you want to see how to convert this into the JSON schema format that tools like Claude use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b7b8a",
   "metadata": {
    "time_run": "5:42:30p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_molecular_weight\n",
      "(smiles: str) -> float\n",
      "\n",
      "    Calculate the molecular weight of a molecule from its SMILES string.\n",
      "\n",
      "    Args:\n",
      "        smiles: A SMILES string representing the molecule\n",
      "\n",
      "    Returns:\n",
      "        The molecular weight in g/mol, or None if the SMILES is invalid\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from fastcore.meta import delegates\n",
    "import inspect\n",
    "\n",
    "# Show the JSON schema that describes the function\n",
    "print(get_molecular_weight.__name__)\n",
    "print(inspect.signature(get_molecular_weight))\n",
    "print(get_molecular_weight.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f469a4",
   "metadata": {},
   "source": [
    "### Lookup SMILES string from Wikidata\n",
    "Wikidata [property https://www.wikidata.org/wiki/Property:P1687](https://www.wikidata.org/wiki/Property:P1687) for [SMILES https://www.wikidata.org/wiki/Q466769](https://www.wikidata.org/wiki/Q466769)   to lookup the SMILES string Wikidata. Note, [Isomemeric SMILES https://www.wikidata.org/wiki/Property:P2017](https://www.wikidata.org/wiki/Property:P2017). As an example [Ethanol https://www.wikidata.org/wiki/Q153](https://www.wikidata.org/wiki/Q153)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2a06c6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Ok. I'm a bit worried you might hallucinate an SMILES String. Could we use Wikidata and the wikidata property for SMILES https://www.wikidata.org/wiki/Property:P1687 to lookup the SMILES string?\n",
    "\n",
    "##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good thinking! Using Wikidata will give us real, verified SMILES strings. \n",
    "\n",
    "To query Wikidata, we can use their SPARQL endpoint. Would you like to:\n",
    "\n",
    "1. Create a function that takes a molecule name (like \"caffeine\" or \"aspirin\") and returns its SMILES string from Wikidata?\n",
    "2. Or create a function that takes a Wikidata QID (like Q60235 for aspirin) and returns the SMILES?\n",
    "\n",
    "Which approach would work better for your demo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ddacee",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "No I want a function that queries the wikidata api given a chemical (ethanol) and returns the SMILES from wikidata.\n",
    "\n",
    "##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Got it! Here's a function that queries Wikidata's SPARQL endpoint to get the SMILES string for a chemical by name:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "def get_smiles_from_wikidata(chemical_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the SMILES string for a chemical from Wikidata.\n",
    "    \n",
    "    Args:\n",
    "        chemical_name: The name of the chemical (e.g., \"ethanol\", \"caffeine\")\n",
    "        \n",
    "    Returns:\n",
    "        The SMILES string, or None if not found\n",
    "    \"\"\"\n",
    "    endpoint = \"https://query.wikidata.org/sparql\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT ?smiles WHERE {{\n",
    "      ?item rdfs:label \"{chemical_name}\"@en .\n",
    "      ?item wdt:P233 ?smiles .\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(endpoint, params={'query': query, 'format': 'json'})\n",
    "    data = response.json()\n",
    "    \n",
    "    if data['results']['bindings']:\n",
    "        return data['results']['bindings'][0]['smiles']['value']\n",
    "    return None\n",
    "```\n",
    "\n",
    "Go ahead and run this. Once it's defined, we can test it with \"ethanol\" and then show how both functions look to an LLM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158a5ac",
   "metadata": {
    "time_run": "5:42:31p"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_smiles_from_wikidata(chemical_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the SMILES string for a chemical from Wikidata.\n",
    "    \n",
    "    Args:\n",
    "        chemical_name: The name of the chemical (e.g., \"ethanol\", \"caffeine\")\n",
    "        \n",
    "    Returns:\n",
    "        The SMILES string, or None if not found\n",
    "    \"\"\"\n",
    "    endpoint = \"https://query.wikidata.org/sparql\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT ?smiles WHERE {{\n",
    "      ?item rdfs:label \"{chemical_name}\"@en .\n",
    "      ?item wdt:P233 ?smiles .\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(endpoint, params={'query': query, 'format': 'json'})\n",
    "    data = response.json()\n",
    "    \n",
    "    if data['results']['bindings']:\n",
    "        return data['results']['bindings'][0]['smiles']['value']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749a2d2",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Ok. How do I test this function?\n",
    "\n",
    "##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Try calling it with a chemical name:\n",
    "\n",
    "```python\n",
    "get_smiles_from_wikidata(\"ethanol\")\n",
    "```\n",
    "\n",
    "This should return the SMILES string for ethanol. Give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362ab18",
   "metadata": {
    "time_run": "5:42:31p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCO'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_smiles_from_wikidata(\"ethanol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e1f2f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Ok. Can you demonstrate how to use &`get_molecular_weight` and &`get_smiles_from_wikidata`\n",
    "\n",
    "##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Now that I have access to both tools via the ampersand-backtick notation, I can use them directly.\n",
    "\n",
    "Let me demonstrate by getting the molecular weight of ethanol:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01A2wbu9AZpXEAwse8D29Qk5\",\n",
    "  \"call\": {\n",
    "    \"function\": \"get_smiles_from_wikidata\",\n",
    "    \"arguments\": {\n",
    "      \"chemical_name\": \"ethanol\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'CCO'\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Now I'll use that SMILES string to calculate the molecular weight:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01DzKUxD8Gjrgby8SpXNUgiL\",\n",
    "  \"call\": {\n",
    "    \"function\": \"get_molecular_weight\",\n",
    "    \"arguments\": {\n",
    "      \"smiles\": \"CCO\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"46.069\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "So ethanol (CCO) has a molecular weight of approximately 46.07 g/mol!\n",
    "\n",
    "This demonstrates how an LLM can:\n",
    "1. Call the first tool to look up the SMILES string from Wikidata\n",
    "2. Use that result to call the second tool to calculate molecular weight\n",
    "3. Chain tools together to accomplish a task\n",
    "\n",
    "Would you like to try another chemical, or shall we look at how to inspect the JSON schema that describes these tools to the LLM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c60931b",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Could we try a harder example like semaglutide (Q27261089)?\n",
    "\n",
    "##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great choice - semaglutide is a much more complex molecule (it's a peptide drug)! \n",
    "\n",
    "Let me try looking it up by name first:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01BNfTpowmE4y4PrZ4FGv7UW\",\n",
    "  \"call\": {\n",
    "    \"function\": \"get_smiles_from_wikidata\",\n",
    "    \"arguments\": {\n",
    "      \"chemical_name\": \"semaglutide\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'CCC(C)C(NC(=O)C(Cc1ccccc1)NC(=O)C(CCC(=O)O)NC(=O)C(CCCCNC(=O)COCCOCCNC(=O)COCCOCCNC(=O)CCC(NC(=O)CCCCCCCCCCCCCCCCC(=O)O)C(=O)O)NC(=O)C(C)NC(=O)C(C)NC(=O)C(CCC(N)=O)NC(=O)CNC(=O)C(CCC(=O)O)NC(=O)C(CC(C)C)NC(=O)C(Cc1ccc(O)cc1)NC(=O)C(CO)NC(=O)C(CO)NC(=O)C(NC(=O)C(CC(=O)O)NC(=O)C(CO)NC(=O)C(NC(=O)C(Cc1ccccc1)NC(=O)C(NC(=O)CNC(=O)C(CCC(=O)O)NC(=O)C(C)(C)NC(=O)C(N)Cc1cnc[nH]1)C(C)O)C(C)O)C(C)C)C(=O)NC(C)C(=O)NC(Cc1c[nH]c2ccccc12)C(=O)NC(CC(C)C)C(=O)NC(C(=O)NC(CCCNC(=N)N)C(=O)NCC(=O)NC(CCCNC(=N)N)C(=O)NCC(=O)O)C(C)C'\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Wow, that's a huge SMILES string! Now let's calculate its molecular weight:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01Kem9PMNQGLx12xnvVjMoL5\",\n",
    "  \"call\": {\n",
    "    \"function\": \"get_molecular_weight\",\n",
    "    \"arguments\": {\n",
    "      \"smiles\": \"CCC(C)C(NC(=O)C(Cc1ccccc1)NC(=O)C(CCC(=O)O)NC(=O)C(CCCCNC(=O)COCCOCCNC(=O)COCCOCCNC(=O)CCC(NC(=O)CCCCCCCCCCCCCCCCC(=O)O)C(=O)O)NC(=O)C(C)NC(=O)C(C)NC(=O)C(CCC(N)=O)NC(=O)CNC(=O)C(CCC(=O)O)NC(=O)C(CC(C)C)NC(=O)C(Cc1ccc(O)cc1)NC(=O)C(CO)NC(=O)C(CO)NC(=O)C(NC(=O)C(CC(=O)O)NC(=O)C(CO)NC(=O)C(NC(=O)C(Cc1ccccc1)NC(=O)C(NC(=O)CNC(=O)C(CCC(=O)O)NC(=O)C(C)(C)NC(=O)C(N)Cc1cnc[nH]1)C(C)O)C(C)O)C(C)C)C(=O)NC(C)C(=O)NC(Cc1c[nH]c2ccccc12)C(=O)NC(CC(C)C)C(=O)NC(C(=O)NC(CCCNC(=N)N)C(=O)NCC(=O)NC(CCCNC(=N)N)C(=O)NCC(=O)O)C(C)C\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"4113.640999999982\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Excellent! Semaglutide has a molecular weight of approximately 4113.64 g/mol - that's a big molecule compared to ethanol's 46.07!\n",
    "\n",
    "This shows how the tools can handle both simple small molecules and complex peptides. What would you like to explore next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58fc105",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "How could the \"inferred from smiles\" Wikidata Entity  https://www.wikidata.org/wiki/Q113907573 be used in this context for provenance annotation?\n",
    "\n",
    "##### ü§ñReplyü§ñ<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "That's a great question about provenance! The \"inferred from SMILES\" entity (Q113907573) is a Wikidata reference qualifier that indicates data was computationally derived from a SMILES string.\n",
    "\n",
    "In your context, you could use it to document that the molecular weight calculation was:\n",
    "1. Based on a SMILES string retrieved from Wikidata\n",
    "2. Computed (not experimentally measured)\n",
    "3. Traceable back to the original data source\n",
    "\n",
    "How would you want to capture this provenance? Some options:\n",
    "\n",
    "1. Return it as metadata alongside the molecular weight (e.g., as a dictionary with the value and provenance info)\n",
    "2. Log it separately for auditing purposes\n",
    "3. Structure it as RDF triples for semantic web applications\n",
    "\n",
    "What fits best with your use case for the CI infrastructure audience?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0d3f5",
   "metadata": {},
   "source": [
    "### General Purpose Terminal Based Tools for Coding Agents\n",
    "\n",
    "- Somewhat based on the [\"Unix Philosophy\" https://en.wikipedia.org/wiki/Unix_philosophy](https://en.wikipedia.org/wiki/Unix_philosophy)\n",
    "- [Anthropic: \"Writing Effective tools for Agents With Agents\" https://www.anthropic.com/engineering/writing-tools-for-agents](https://www.anthropic.com/engineering/writing-tools-for-agents)\n",
    "\n",
    "Tools available from `fastcore.tools`:\n",
    "\n",
    "- &`rg`: Run the `rg` command with the args in `argstr` (no need to backslash escape)\n",
    "- &`sed`: Run the `sed` command with the args in `argstr` (e.g for reading a section of a file)\n",
    "- &`view`: View directory or file contents with optional line range and numbers\n",
    "- &`create`: Creates a new file with the given content at the specified path\n",
    "- &`insert`: Insert new_str at specified line number\n",
    "- &`str_replace`: Replace first occurrence of old_str with new_str in file\n",
    "- &`strs_replace`: Replace for each str pair in old_strs,new_strs\n",
    "- &`replace_lines`: Replace lines in file using start and end line-numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35a7f68",
   "metadata": {},
   "source": [
    "### Model Context Protocol (MCP) Standardized (Web)API for \"Tools\"\n",
    "\n",
    "- [\"What is Model Context Protocol?\" https://modelcontextprotocol.io/docs/getting-started/intro](https://modelcontextprotocol.io/docs/getting-started/intro)\n",
    "\n",
    "> \"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems.\n",
    "\n",
    ">Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)‚Äîenabling them to access key information and perform tasks.\n",
    "\n",
    "> Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems.\"\n",
    "\n",
    "* Main mechanism for connecting Web API interfaces, Relational Databases and Documentation to LLM Agents\n",
    "* Claude, Claude Code, ChatGPT, Visual Studio Code support adding MCP servers as tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f311d9",
   "metadata": {},
   "source": [
    "## Agents and \"Agentic\" Workflows\n",
    "- [Sequoia AI Ascent event, \"What's next for AI agentic workflows ft. Andrew Ng of AI Fund\", https://youtu.be/sal78ACtGTc](https://youtu.be/sal78ACtGTc)\n",
    "- [Andrew Ng, \"The Batch\", Issue 253, June 12, 2024, https://www.deeplearning.ai/the-batch/issue-253/](https://www.deeplearning.ai/the-batch/issue-253/)\n",
    "\n",
    "> Rather than having to choose whether or not something is an agent in a binary way, I thought, it would be more useful to think of systems as being agent-like to different degrees. Unlike the noun ‚Äúagent,‚Äù the adjective ‚Äúagentic‚Äù allows us to contemplate such systems and include all of them in this growing movement.\n",
    "\n",
    "Andrew Ng Defined four \"Agentic Patterns\"\n",
    "- Reflection \n",
    "- Tool use\n",
    "- Planning\n",
    "- Multi-agent collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716a095",
   "metadata": {},
   "source": [
    "### However, this hasn't stopped the discussions on what is \"Agentic\"\n",
    "\n",
    "> \"An LLM agent runs tools in a loop to achieve a goal.\"\n",
    "\n",
    "- [I think ‚Äúagent‚Äù may finally have a widely enough agreed upon definition to be useful jargon now](https://simonwillison.net/2025/Sep/18/agents/)\n",
    "\n",
    "![](./images/agentic.jpeg)\n",
    "- [Matt Pocock, X, https://x.com/mattpocockuk/status/1975655749251436738](https://x.com/mattpocockuk/status/1975655749251436738)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00e108",
   "metadata": {},
   "source": [
    "### \"Vibe Coding\" and \"YOLO Mode\"\n",
    "\n",
    "Vibe Coding: [Mirriam-Webster](https://www.merriam-webster.com/slang/vibe-coding) and [Wikipedia](https://en.wikipedia.org/wiki/Vibe_coding) coined by Andrej Karpathy\n",
    "> \"Vibe coding (also written as vibecoding) is a recently-coined term for the practice of writing code, making web pages, or creating apps, by just telling an AI program what you want, and letting it create the product for you. In vibe coding the coder does not need to understand how or why the code works, and often will have to accept that a certain number of bugs and glitches will be present. The verb form of the word is vibe code.\"\n",
    "\n",
    "> \"YOLO mode,\" in the context of vibe coding, is an approach where a developer gives an autonomous AI agent complete control to execute tasks without requiring human permission. The name comes from the acronym YOLO (\"You Only Live Once\"), and it represents a high-risk, high-speed approach to AI-assisted development. \n",
    "\n",
    "- [Chika Ihejimba, PhD, \"Vibe Coding\", Apr 09, 2025,https://chikaihejimba.substack.com/p/vibe-coding](https://chikaihejimba.substack.com/p/vibe-coding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320416e8",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG)\n",
    "Imagine you‚Äôre building a giant language model (LLM) like ChatGPT. It‚Äôs been trained on lots of text, so it ‚Äúknows‚Äù a lot of patterns. But two problems still bite you:\n",
    "\n",
    "- Memory / scale: The model‚Äôs internal weights can only capture so much. If you want up-to-date facts, niche documents, very large corpora, you can‚Äôt just cram all of that into the params.\n",
    "- Hallucination / accuracy: Pure generation means the model might ‚Äúmake things up‚Äù or approximate rather than fetch exact info.\n",
    "\n",
    "So the idea: let the model retrieve relevant documents / passages at inference time, then feed those as context into the LLM so it can generate an answer grounded in real retrieved material. That‚Äôs RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac6e86",
   "metadata": {},
   "source": [
    "### RAG pieces (modular breakdown)\n",
    "\n",
    "**The retrieval system:**\n",
    "- You have a large corpus (documents, web pages, knowledge-base).\n",
    "- Build an index (e.g., embedding index, vector store) so you can map a query ‚Üí ‚Äútop-k relevant documents‚Äù.\n",
    "- Techniques: embedding models (convert query + docs to vectors), nearest neighbour search (FAISS, Annoy, HNSW).\n",
    "- Example: embed each document d_i ‚Üí v_i, embed query q ‚Üí v_q, then find docs whose vectors v_i are near v_q (cosine similarity).\n",
    "- Output: a small set of snippets, passages, maybe full docs: D = \\{d_1, d_2, \\dots\\}.\n",
    "\n",
    "**The generation model (LLM):**\n",
    "- A transformer-based model trained for text generation (autoregressive, or sequence to sequence).\n",
    "- At inference, you concatenate or otherwise provide the retrieved docs + the user query (and maybe instructions) as input.\n",
    "- The LLM uses those docs as context to generate a response.\n",
    "\n",
    "**The glue / orchestration:**\n",
    "- You need to design how the docs are inserted into the prompt: inline, chunked, ranked, maybe with metadata (source, doc id).\n",
    "- You might filter/re-rank docs (only top 5, or only high quality).\n",
    "- You might decide how to prompt the model so it ‚Äúuses‚Äù the docs (e.g., ‚ÄúUsing the passages below, answer the question‚Äù, or ‚ÄúYou are an expert, refer to the sources‚Äù).\n",
    "- You might include a source attribution mechanism (so answer can cite which doc it came from)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5430d",
   "metadata": {},
   "source": [
    "### GraphRAG\n",
    "\n",
    "So, you already know **RAG (Retrieval-Augmented Generation)**.\n",
    "It solves ‚Äúmy LLM can‚Äôt remember the whole internet‚Äù by adding a retriever that fetches relevant chunks from a **vector database** ‚Äî little islands of meaning.\n",
    "\n",
    "But here‚Äôs the problem:\n",
    "\n",
    "> ‚ÄúThe world is not a pile of paragraphs. It‚Äôs a web of relationships.‚Äù\n",
    "\n",
    "Documents reference each other, entities co-occur, knowledge is relational.\n",
    "Plain RAG sees text as isolated chunks.\n",
    "GraphRAG connects them into a **knowledge graph** ‚Äî a structure that encodes who is related to what and how.\n",
    "\n",
    "So instead of searching over disjoint vectors, we search and reason over a **graph topology**.\n",
    "\n",
    "üåê GraphRAG Idea:\n",
    "\n",
    "- Represent knowledge as a **graph** (entities + relations).\n",
    "- Retrieval = **traversal**, not just vector search.\n",
    "- Feed connected **subgraphs** (not isolated chunks) to the LLM.\n",
    "\n",
    "<hr>\n",
    "\n",
    "- [Microsoft Research, \"GraphRAG: Unlocking LLM discovery on narrative private data\" (February 13, 2024), https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abbfff",
   "metadata": {},
   "source": [
    "### GraphRAG Example GraphRAG for Scientific Insight (Wikidata)**\n",
    "\n",
    "**Question (user query):**\n",
    "*‚ÄúWhich proteins interact with BRCA1 and are linked to breast cancer?‚Äù*\n",
    "\n",
    "**Why GraphRAG (intuition):**\n",
    "\n",
    "* RAG pulls **text chunks** ‚Üí good facts, weak relationships\n",
    "* GraphRAG walks a **knowledge graph** (entities + relations) ‚Üí multi-hop, explainable answers\n",
    "\n",
    "**We‚Äôll click real nodes & relations:**\n",
    "\n",
    "* **BRCA1** (human tumor-suppressor) ‚Üí [https://www.wikidata.org/wiki/Q227339](https://www.wikidata.org/wiki/Q227339) ([Wikidata][1])\n",
    "* **Breast cancer** ‚Üí [https://www.wikidata.org/wiki/Q128581](https://www.wikidata.org/wiki/Q128581) ([Wikidata][2])\n",
    "* Property **‚Äúinteracts with‚Äù** (`P129`) shown on BRCA1‚Äôs page (scroll to statements)\n",
    "* Property **‚Äúgenetic association‚Äù** (`P2293`) definition ‚Üí [https://www.wikidata.org/wiki/Property:P2293](https://www.wikidata.org/wiki/Property:P2293) ([Wikidata][3])\n",
    "\n",
    "**Example path you can inspect by clicking through BRCA1‚Äôs statements:**\n",
    "\n",
    "```\n",
    "BRCA1  --(interacts with/P129)-->  RAD51 family protein\n",
    "RAD51* --(genetic association/P2293)--> Breast cancer\n",
    "```\n",
    "\n",
    "Helpful RAD51 paralogs (human):\n",
    "\n",
    "* **RAD51C** ‚Üí [https://www.wikidata.org/wiki/Q18031015](https://www.wikidata.org/wiki/Q18031015) ([Wikidata][4])\n",
    "* **RAD51B** ‚Üí [https://www.wikidata.org/wiki/Q18031016](https://www.wikidata.org/wiki/Q18031016) ([Wikidata][5])\n",
    "\n",
    "> Tip: On the BRCA1 page, use the **‚ÄúStatements‚Äù** section to find ‚Äúinteracts with,‚Äù click the target protein item, then look for disease associations on that protein‚Äôs page.\n",
    "\n",
    "** Generated entirely by ChatGPT using thinking, reflection and tool use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d1935",
   "metadata": {},
   "source": [
    "### GraphRAG Agentic Flow\n",
    "\n",
    "**1) Retrieve entry points (semantic search over labels/aliases):**\n",
    "Find BRCA1 and nearby nodes (proteins it *interacts with*) via their Wikidata pages.\n",
    "\n",
    "* BRCA1 ‚Üí open statements ‚Üí find **P129 (interacts with)** targets. ([Wikidata][1])\n",
    "\n",
    "**2) Expand neighborhood (graph traversal):**\n",
    "From those proteins (e.g., RAD51 family), follow **P2293 (genetic association)** to diseases (e.g., breast cancer).\n",
    "\n",
    "* P2293 docs ‚Üí scope & meaning. ([Wikidata][3])\n",
    "* Breast cancer item for cross-check. ([Wikidata][2])\n",
    "\n",
    "**3) Serialize subgraph for the LLM (prompt context):**\n",
    "Minimal triples you can copy from the pages you clicked:\n",
    "\n",
    "```\n",
    "<BRCA1> --interacts with--> <RAD51C>\n",
    "<RAD51C> --genetic association--> <Breast cancer>\n",
    "```\n",
    "\n",
    "(You can substitute **RAD51B** similarly.) ([Wikidata][4])\n",
    "\n",
    "**4) Generate grounded answer (LLM prompt):**\n",
    "‚ÄúUsing these Wikidata facts (with Q-IDs/links), explain how BRCA1‚Äôs interaction partners connect to breast cancer and cite the items.‚Äù\n",
    "\n",
    "**TL;DR:**\n",
    "\n",
    "```\n",
    "LLM weights ‚Üí baked patterns\n",
    "RAG        ‚Üí fetch similar text\n",
    "GraphRAG   ‚Üí walk the graph (entities/relations), then generate\n",
    "= Retrieval-Augmented Reasoning\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc3996",
   "metadata": {},
   "source": [
    "## \"Prompt Engineering\" vs \"Context Engineering\"\n",
    "\n",
    "> \"Context refers to the set of tokens included when sampling from a large-language model (LLM). The engineering problem at hand is optimizing the utility of those tokens against the inherent constraints of LLMs in order to consistently achieve a desired outcome. Effectively wrangling LLMs often requires thinking in context ‚Äî in other words: considering the holistic state available to the LLM at any given time and what potential behaviors that state might yield.\"\n",
    "\n",
    "![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Ffaa261102e46c7f090a2402a49000ffae18c5dd6-2292x1290.png&w=3840&q=75)\n",
    "---\n",
    "- [Anthropic Engineering, \"Effective context engineering for AI agents\", Sep 29, 2025, https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e72821",
   "metadata": {},
   "source": [
    "## FAIR Data in the Context of Generative AI\n",
    "\n",
    "[GoFAIR FAIR principles](https://www.go-fair.org/fair-principles/)\n",
    "- **F**indable\n",
    "- **A**ccessible\n",
    "- **I**nteroperable\n",
    "- **R**eusable\n",
    "\n",
    "> \"Humans, however, are not the only critical stakeholders in the milieu of scientific data. Similar problems are encountered by the applications and computational agents that we task to undertake data retrieval and analysis on our behalf. These ‚Äòcomputational stakeholders‚Äô are increasingly relevant, and demand as much, or more, attention as their importance grows. One of the grand challenges of data-intensive science, therefore, is to improve knowledge discovery through assisting both humans, and their computational agents, in the discovery of, access to, and integration and analysis of, task-appropriate scientific data and other scholarly digital objects.\"\n",
    "\n",
    ">\"It is for this reason that humans increasingly rely on computational agents to undertake discovery and integration tasks on their behalf. This necessitates machines to be capable of autonomously and appropriately acting when faced with the wide range of types, formats, and access-mechanisms/protocols that will be encountered during their **self-guided exploration** of the global data ecosystem. It also necessitates that the machines keep an exquisite **record of provenance** such that the data they are collecting can be accurately and adequately cited. Assisting these agents, therefore, is a critical consideration for all participants in the data management and stewardship process‚Äîfrom researchers and data producers to data repository hosts.\"\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "- [M. D. Wilkinson et al., ‚ÄúThe FAIR Guiding Principles for scientific data management and stewardship,‚Äù Sci Data, vol. 3, p. 160018, Mar. 2016.https://www.nature.com/articles/sdata201618](https://www.nature.com/articles/sdata201618)"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
