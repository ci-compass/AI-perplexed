{
 "cells": [
  {
   "cell_type": "raw",
   "id": "49a58314",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"A guide to Generative AI for the Perplexed\"\n",
    "date: 2025-10-29\n",
    "author:\n",
    "  - name: Charles F. Vardeman II\n",
    "    id: cfv\n",
    "    orcid: 0000-0002-1825-0097\n",
    "    email: cvardema@nd.edu\n",
    "    affiliation:\n",
    "      - name: Center for Research Computing, University of Notre Dame\n",
    "        city: Notre Dame\n",
    "        state: IN\n",
    "        url: https://crc.nd.edu\n",
    "      - name: CI-Compass\n",
    "        url: https://ci-compass.org\n",
    "keywords:\n",
    "  - Generative AI in Science\n",
    "  - Science Agents\n",
    "license: \"CC BY\"\n",
    "citation:\n",
    "  type: document\n",
    "  container-title: Zenodo\n",
    "  doi: 10.5281/zenodo.10815117\n",
    "links:\n",
    "  - text: \"Video Presentation\"\n",
    "    url: \"https://youtube.com/...\"\n",
    "  - text: \"GitHub Repository\"\n",
    "    url: \"https://github.com/ci-compass/AI-perplexed\"\n",
    "funding: \"This project is supported by the U.S. National Science Foundation Office of Advanced Cyberinfrastructure in the Directorate for Computer Information Science under Grant #2127548\"\n",
    "format:\n",
    "  html:\n",
    "    toc: true\n",
    "    code-fold: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49926eb8",
   "metadata": {},
   "source": [
    "## GitHub CI-compass Organization\n",
    "- [GitHub Link: https://github.com/ci-compass/AI-perplexed](https://github.com/ci-compass/AI-perplexed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984505e3",
   "metadata": {},
   "source": [
    "# A guide to Generative AI for the Perplexed\n",
    "\n",
    "> This video is meant to be a rough guide to some of the concepts and to help understand generative AI and preparation for the NSF CyberInfrastructure Center of Excellence [CI-Compass](https://ci-compass.org/) [Virtual Workshop - AI Meets CI: Intelligent Infrastructure for Major & Midscale Facilities](https://ci-compass.org/news-and-events/events/virtual-workshop-ai-meets-ci-intelligent-infrastructure-for-major-and-midscale-facilities/). The purpose is to start from the beginning and try to de-mystify **chatbot** based Generative AI.\n",
    "\n",
    "![](https://ci-compass.org/assets/629872/300x/ai_meets_ci_recreation_1.png)\n",
    "\n",
    "## Chat based generative AI\n",
    "\n",
    "### Chat interface\n",
    "- [OpenAI ChatGPT](https://chatgpt.com/)\n",
    "- [Anthropic Claude](https://claude.ai/new)\n",
    "- [Google Gemini](https://gemini.google.com/)\n",
    "\n",
    "### Terminal Based Coding Agents\n",
    "- [Anthropic Claude Code Cli](https://www.claude.com/product/claude-code)\n",
    "- [OpenAI Codex Cli](https://github.com/openai/codex)\n",
    "- [Google Gemini Cli](https://geminicli.com/)\n",
    "- [Microsoft Visual Studio Code](https://code.visualstudio.com/)\n",
    "\n",
    "### Notebook Based AI\n",
    "- [AnswerAI SolveIT](https://solve.it.com)\n",
    "- [Google Collab](https://developers.googleblog.com/en/data-science-agent-in-colab-with-gemini/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef43300",
   "metadata": {},
   "source": [
    "## Andrej Karpathy \"Deep Dive into LLMs like ChatGPT\"\n",
    "![](./images/karpathy-yt.png)\n",
    "\n",
    "- [Deep Dive into LLMs like ChatGPT: https://youtu.be/7xTGNNLPyMI](https://youtu.be/7xTGNNLPyMI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e1191d",
   "metadata": {},
   "source": [
    "## Andrej Karpathy - How I use LLMs\"\n",
    "![](./images/karpathy-yt-use.png)\n",
    "\n",
    "- [How I use LLMs YT link: https://youtu.be/EWvNQjAaOHw](https://youtu.be/EWvNQjAaOHw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf28ba6",
   "metadata": {},
   "source": [
    "## \"Foundation Models\"\n",
    "\n",
    "- [What is are Foundation Models? https://aws.amazon.com/what-is/foundation-models/](https://aws.amazon.com/what-is/foundation-models/)\n",
    "- Notion of \"Transfer Learning\" - That is you can start with a pretrained network for a new application or task.\n",
    "    - [J. Howard and S. Ruder, “Universal Language Model Fine-tuning for Text Classification,” in Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 2018, pp. 328–339.https://aclanthology.org/P18-1031/](https://aclanthology.org/P18-1031/)\n",
    "\n",
    "<hr>\n",
    "\n",
    "- **Multimodal \"Text\" models:** GPT-5; Anthropic Claude Opus, Sonnet; Google Gemini 2.5; Meta LAMMA, Deepseek R1\n",
    "- **Image or Video Generation from text:** OpenAI Sora, [Google Imagen](https://imagen.research.google/)\n",
    "- **Science Foundation Models:** [Futurehouse ether0](https://www.futurehouse.org/research-announcements/ether0-a-scientific-reasoning-model-for-chemistry)\n",
    "    - [M. Hu et al., “A survey of scientific Large Language Models: From data foundations to agent frontiers,” arXiv [cs.CL], 28-Aug-2025. https://arxiv.org/abs/2508.21148](https://arxiv.org/abs/2508.21148)\n",
    "    - [Towards a Physics Foundation Model https://arxiv.org/html/2509.13805v2](https://arxiv.org/html/2509.13805v2)\n",
    "    - [H. Cui et al., “Towards multimodal foundation models in molecular cell biology,” Nature, vol. 640, no. 8059, pp. 623–633, Apr. 2025.https://www.nature.com/articles/s41586-025-08710-y](https://www.nature.com/articles/s41586-025-08710-y)\n",
    "    - [Nurips 2024: Foundation Models for Science: Progress, Opportunities, and Challenges](https://neurips.cc/virtual/2024/workshop/84714)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb5a18b",
   "metadata": {},
   "source": [
    "### \"Groking\" -- Memorization vs Generalization\n",
    "> \"Out of Distribution Phenomenon\" where  model initially overfits to the training set, and then suddenly generalizes to unseen test samples after continuous training\n",
    "\n",
    "![An interactive introduction to grokking and mechanistic interpretability](https://res.cloudinary.com/lesswrong-2-0/image/upload/f_auto,q_auto/v1/mirroredImages/XpCnhaAQrssq8tJBG/rfpm8jhcd5kog1mqi8jn)\n",
    "\n",
    "- [An interactive introduction to grokking and mechanistic interpretability](https://www.alignmentforum.org/posts/XpCnhaAQrssq8tJBG/an-interactive-introduction-to-grokking-and-mechanistic)\n",
    "- [Do Machine Learning Models Memorize or Generalize? https://pair.withgoogle.com/explorables/grokking/](https://pair.withgoogle.com/explorables/grokking/)\n",
    "- [Anthropic Transformer Circuits](https://transformer-circuits.pub/)\n",
    "- [Y. Tian, “Provable scaling laws of feature emergence from learning dynamics of grokking,” arXiv [cs.LG], 30-Sept-2025.https://arxiv.org/html/2509.21519v3](https://arxiv.org/html/2509.21519v3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03f9ec9",
   "metadata": {},
   "source": [
    "## \"Context Window -- Trained Model\"\n",
    "Think of an LLM as a kind of supercharged text predictor: you give it a sequence of tokens (words or subwords) and it predicts the next token, then the next, etc. What we call the context window is simply how many tokens the model can look back at when making each prediction.\n",
    "\n",
    "- If a model has a context window of, say, 4,096 tokens, then when it’s about to predict token N, it only “knows” about tokens N-4,095 through N-1 (plus whatever internal state) — it cannot directly “see” tokens older than that.\n",
    "\n",
    "- Everything the model uses to ground its prediction must be inside that window — the user prompt, the system instructions, examples, retrieved documents, conversation history, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be634c62",
   "metadata": {},
   "source": [
    "### Why does the Context Window Matter?\n",
    "1. **Scope of what the model knows in this invocation -- Stateless Model**\n",
    "> Because the model cannot remember everything ever said, only what fits into its window — if you want it to reference a piece of text, you must include it (or a compressed version of it) in the window.\n",
    "\n",
    "2. **Management of context = performance trade-offs**\n",
    "> The more tokens you feed (longer history, more retrieved docs, more examples), the richer the information the model has — but you are limited by the window size. If you exceed it, older tokens get truncated (lost). If you fill it with irrelevant stuff, you can confuse the model (context noise) rather than help it. Karpathy calls this “the delicate art and science of filling the context window with just the right information for the next step.”\n",
    "\n",
    "3. **Analogy: human coworker with short-term memory**\n",
    "> Karpathy uses an analogy: the LLM is like a coworker who has anterograde amnesia — they forget everything beyond a short timeframe. So if you want them to reference something older, you must remind them (i.e., re-include it in the window)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb98a0c2",
   "metadata": {},
   "source": [
    "### Multimodal Context Window\n",
    ">Now imagine we extend that idea: Instead of feeding the model just text tokens, we also feed in image tokens, audio tokens, video frame tokens, sensor tokens, etc. \n",
    "\n",
    "**Each modality has its own tokenizer:**\n",
    "\n",
    "- Text → word/subword tokens\n",
    "\n",
    "- Images → small patch tokens (like 16×16 pixels each)\n",
    "\n",
    "- Audio → waveform chunks or spectrogram tokens\n",
    "\n",
    "All of those get projected into the same vector space and concatenated into one long sequence.\n",
    "That sequence is the multimodal context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5670dfc0",
   "metadata": {
    "time_run": "5:42:30p"
   },
   "outputs": [],
   "source": [
    "from dialoghelper import *\n",
    "fc_tool_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee920c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b328965",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "Tools available from `fastcore.tools`:\n",
    "\n",
    "- &`rg`: Run the `rg` command with the args in `argstr` (no need to backslash escape)\n",
    "- &`sed`: Run the `sed` command with the args in `argstr` (e.g for reading a section of a file)\n",
    "- &`view`: View directory or file contents with optional line range and numbers\n",
    "- &`create`: Creates a new file with the given content at the specified path\n",
    "- &`insert`: Insert new_str at specified line number\n",
    "- &`str_replace`: Replace first occurrence of old_str with new_str in file\n",
    "- &`strs_replace`: Replace for each str pair in old_strs,new_strs\n",
    "- &`replace_lines`: Replace lines in file using start and end line-numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd1f3e",
   "metadata": {
    "time_run": "5:42:30p"
   },
   "outputs": [],
   "source": [
    "from fastcore.tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dfc81e",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "Tools available from `fastcore.tools`:\n",
    "\n",
    "- &`rg`: Run the `rg` command with the args in `argstr` (no need to backslash escape)\n",
    "- &`sed`: Run the `sed` command with the args in `argstr` (e.g for reading a section of a file)\n",
    "- &`view`: View directory or file contents with optional line range and numbers\n",
    "- &`create`: Creates a new file with the given content at the specified path\n",
    "- &`insert`: Insert new_str at specified line number\n",
    "- &`str_replace`: Replace first occurrence of old_str with new_str in file\n",
    "- &`strs_replace`: Replace for each str pair in old_strs,new_strs\n",
    "- &`replace_lines`: Replace lines in file using start and end line-numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec67704",
   "metadata": {
    "time_run": "5:42:30p"
   },
   "outputs": [],
   "source": [
    "tool_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2dd6f",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "Tools available from `dialoghelper`:\n",
    "\n",
    "- &`curr_dialog`: Get the current dialog info.\n",
    "- &`msg_idx`: Get absolute index of message in dialog.\n",
    "- &`add_html`: Send HTML to the browser to be swapped into the DOM using hx-swap-oob.\n",
    "- &`find_msg_id`: Get the current message id.\n",
    "- &`find_msgs`: Find messages in current specific dialog that contain the given information.\n",
    "  - (solveit can often get this id directly from its context, and will not need to use this if the required information is already available to it.)\n",
    "- &`read_msg`: Get the message indexed in the current dialog.\n",
    "  - To get the exact message use `n=0` and `relative=True` together with `msgid`.\n",
    "  - To get a relative message use `n` (relative position index).\n",
    "  - To get the nth message use `n` with `relative=False`, e.g `n=0` first message, `n=-1` last message.\n",
    "- &`del_msg`: Delete a message from the dialog.\n",
    "- &`add_msg`: Add/update a message to the queue to show after code execution completes.\n",
    "- &`update_msg`: Update an existing message.\n",
    "- &`url2note`: Read URL as markdown, and add a note below current message with the result\n",
    "- &`msg_insert_line`: Insert text at a specific location in a message.\n",
    "- &`msg_str_replace`: Find and replace text in a message.\n",
    "- &`msg_strs_replace`: Find and replace multiple strings in a message.\n",
    "- &`msg_replace_lines`: Replace a range of lines in a message with new content.\n",
    "  - Always first use `read_msg( msgid=msgid, n=0, relative=True, nums=True)` to view the content with line numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ff4bef",
   "metadata": {},
   "source": [
    "### \"Thinking Models and Chain of Thought\" (Deepseek-R1 from Karpathy Video)\n",
    "![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgVgTjwA0IzKekrQoMziCmDXjO10QKjdDdzK1Oj8bZToPOI6VjVzTKXZ6vnWvAGOdVnWznJK2ZZjfBuTLojobayI_yrvlFzE3dCErF2j5wKLGFWAkuGP9-r-hMrqFivnjYhbCIu7HFINSmHu4wUjlKHfJxWHZ8Y7CYUowWvxTeRJhQEAUswGh2fUd3VHA/s2500/chainofthought.png)\n",
    "\n",
    "- [Language Models Perform Reasoning via Chain of Thought (May 2022)https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/](https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c7145b",
   "metadata": {},
   "source": [
    "## ReACT\n",
    "![](https://react-lm.github.io/files/diagram.png)\n",
    "\n",
    "- [ReAct: Synergizing Reasoning and Acting in Language Models Blog: https://react-lm.github.io/](https://react-lm.github.io/)\n",
    "- [S. Yao et al., “ReAct: Synergizing reasoning and acting in language models,” Int Conf Learn Represent, vol. abs/2210.03629, Oct. 2022. https://openreview.net/forum?id=WE_vluYUL-X](https://openreview.net/forum?id=WE_vluYUL-X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7e98f0",
   "metadata": {},
   "source": [
    "## Tool Use\n",
    "> Tool use is when a language model learns or is prompted to call external functions — like calculators, search engines, databases, or other APIs — to augment its own capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b368aaf3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "So I would like to demonstrate tool use within the Solvit notebook, which is meant to be sort of this presentation walkthrough of LLM based topics. So I'd like to use essentially a simple definition or a simple Python function, and then use fast query-tills to explain how you can get essentially cast the function to something the LLM understands in terms of JSON. And then lastly, sort of demonstrate how you can then use the tool within your context.\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great idea! Let's build this demonstration step by step. We'll create a simple Python function, show how to make it \"LLM-readable\" using JSON schema, and then demonstrate tool use in action.\n",
    "\n",
    "Let's start with a simple example function. What kind of function would you like to use for the demonstration? Some options:\n",
    "\n",
    "1. A calculator function (e.g., compound interest, unit conversion)\n",
    "2. A data lookup function (e.g., get information about something)\n",
    "3. A text processing function (e.g., count words, analyze sentiment)\n",
    "4. Something domain-specific for your audience (CI/research computing related?)\n",
    "\n",
    "What would work best for your presentation context?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39965fbf",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Yeah, I think something domain specific might be kind of good. So I have RD-Kit installed. Could we walk through step by step in the solvit sort of way of how to create a function for RD-Kit?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! RDKit is great for this - it's domain-specific and will resonate with your research computing audience.\n",
    "\n",
    "Let's start simple. What kind of molecular operation would you like to demonstrate? Here are some straightforward options:\n",
    "\n",
    "1. Calculate molecular weight from a SMILES string\n",
    "2. Count the number of atoms in a molecule\n",
    "3. Check if a SMILES string is valid\n",
    "4. Calculate LogP (lipophilicity)\n",
    "\n",
    "Which one sounds good, or do you have another RDKit function in mind?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b8dfc3",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Let's calculate molecular weight. Go ahead and write the function. After we write the function, we will want to use fastcore to illustrate \"what the function looks like\" to solveit.\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Here's a simple function to calculate molecular weight from a SMILES string:\n",
    "\n",
    "```python\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "def get_molecular_weight(smiles: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the molecular weight of a molecule from its SMILES string.\n",
    "    \n",
    "    Args:\n",
    "        smiles: A SMILES string representing the molecule\n",
    "        \n",
    "    Returns:\n",
    "        The molecular weight in g/mol, or None if the SMILES is invalid\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    return Descriptors.MolWt(mol)\n",
    "```\n",
    "\n",
    "Go ahead and run this to define the function. Once you've done that, let me know and we'll use fastcore to show what this function looks like to an LLM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad31b9a",
   "metadata": {
    "time_run": "5:42:30p"
   },
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "def get_molecular_weight(smiles: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the molecular weight of a molecule from its SMILES string.\n",
    "    \n",
    "    Args:\n",
    "        smiles: A SMILES string representing the molecule\n",
    "        \n",
    "    Returns:\n",
    "        The molecular weight in g/mol, or None if the SMILES is invalid\n",
    "    \"\"\"\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None:\n",
    "        return None\n",
    "    return Descriptors.MolWt(mol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c380990",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "OK. How do I demonstrate what this function looks like to solveit?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "To show what this function looks like to an LLM, you can use fastcore's tooling. Try running:\n",
    "\n",
    "```python\n",
    "from fastcore.meta import delegates\n",
    "import inspect\n",
    "\n",
    "# Show the JSON schema that describes the function\n",
    "print(get_molecular_weight.__name__)\n",
    "print(inspect.signature(get_molecular_weight))\n",
    "print(get_molecular_weight.__doc__)\n",
    "```\n",
    "\n",
    "This will show you the basic elements. But to see the actual JSON schema format that gets sent to an LLM, you'll want to use the schema generation. Do you want to see how to convert this into the JSON schema format that tools like Claude use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703b7b8a",
   "metadata": {
    "time_run": "5:42:30p"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_molecular_weight\n",
      "(smiles: str) -> float\n",
      "\n",
      "    Calculate the molecular weight of a molecule from its SMILES string.\n",
      "\n",
      "    Args:\n",
      "        smiles: A SMILES string representing the molecule\n",
      "\n",
      "    Returns:\n",
      "        The molecular weight in g/mol, or None if the SMILES is invalid\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from fastcore.meta import delegates\n",
    "import inspect\n",
    "\n",
    "# Show the JSON schema that describes the function\n",
    "print(get_molecular_weight.__name__)\n",
    "print(inspect.signature(get_molecular_weight))\n",
    "print(get_molecular_weight.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b746af",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "What does the delegates function do? Could you look up the documentation at https://fastcore.fast.ai/docments.html and https://fastcore.fast.ai/meta.html and https://fastcore.fast.ai/tools.html\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_011UYCzx2qa18kbe6Frviu5c\",\n",
    "  \"call\": {\n",
    "    \"function\": \"read_url\",\n",
    "    \"arguments\": {\n",
    "      \"url\": \"https://fastcore.fast.ai/docments.html\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'[ ](./index.html) [ fastcore ](./index.html)\\\\n\\\\n  * [ __ ](https://github.com/fastai/fastcore)\\\\n  * [ __ ](https://x.com/fastdotai)\\\\n\\\\n__\\\\n\\\\n  1. [Docments](./docments.html)\\\\n\\\\n[ ](./index.html)\\\\n\\\\n  * [ Welcome to fastcore](./index.html)\\\\n\\\\n  * [ A tour of fastcore](./tour.html)\\\\n\\\\n  * [ Test](./test.html)\\\\n\\\\n  * [ Basic functionality](./basics.html)\\\\n\\\\n  * [ Foundation](./foundation.html)\\\\n\\\\n  * [ Utility functions](./xtras.html)\\\\n\\\\n  * [ Parallel](./parallel.html)\\\\n\\\\n  * [ Network functionality](./net.html)\\\\n\\\\n  * [ Docments](./docments.html)\\\\n\\\\n  * [ Meta](./meta.html)\\\\n\\\\n  * [ Script - CLI](./script.html)\\\\n\\\\n  * [ XDG](./xdg.html)\\\\n\\\\n  * [ Style](./style.html)\\\\n\\\\n  * [ XML](./xml.html)\\\\n\\\\n  * [ Create delegated pyi](./py2pyi.html)\\\\n\\\\n  * [ External modules](./external.html)\\\\n\\\\n  * [ LLM tools](./tools.html)\\\\n\\\\n## On this page\\\\n\\\\n  * Why?\\\\n  * Numpy docstring helper functions\\\\n    * docstring\\\\n    * parse_docstring\\\\n    * isdataclass\\\\n    * get_dataclass_source\\\\n    * get_source\\\\n    * get_name\\\\n    * qual_name\\\\n  * Docments\\\\n    * docments\\\\n    * sig2str\\\\n  * Extract docstrings\\\\n    * extract_docstrings\\\\n\\\\n  * [__Report an issue](https://github.com/AnswerDotAI/fastcore/issues/new)\\\\n\\\\n## Other Formats\\\\n\\\\n  * [ __CommonMark](docments.html.md)\\\\n\\\\n# Docments\\\\n\\\\nDocument parameters using comments.\\\\n\\\\n[`docments`](https://fastcore.fast.ai/docments.html#docments) provides programmatic access to comments in function parameters and return types. It can be used to create more developer-friendly documentation, CLI, etc tools.\\\\n\\\\n## Why?\\\\n\\\\nWithout docments, if you want to document your parameters, you have to repeat param names in docstrings, since they\\u2019re already in the function signature. The parameters have to be kept synchronized in the two places as you change your code. Readers of your code have to look back and forth between two places to understand what\\u2019s happening. So it\\u2019s more work for you, and for your users.\\\\n\\\\nFurthermore, to have parameter documentation formatted nicely without docments, you have to use special magic docstring formatting, often with [odd quirks](https://stackoverflow.com/questions/62167540/why-do-definitions-have-a-space-before-the-colon-in-numpy-docstring-sections), which is a pain to create and maintain, and awkward to read in code. For instance, using [numpy-style documentation](https://numpydoc.readthedocs.io/en/latest/format.html):\\\\n\\\\n```\\\\ndef add_np(a:int, b:int=0)->int:\\\\n    \\\"\\\"\\\"The sum of two numbers.\\\\n\\\\n    Used to demonstrate numpy-style docstrings.\\\\n\\\\nParameters\\\\n----------\\\\na : int\\\\n    the 1st number to add\\\\nb : int\\\\n    the 2nd number to add (default: 0)\\\\n\\\\nReturns\\\\n-------\\\\nint\\\\n    the result of adding `a` to `b`\\\"\\\"\\\"\\\\n    return a+b\\\\n```\\\\n\\\\n __\\\\n\\\\nBy comparison, here\\u2019s the same thing using docments:\\\\n\\\\n```\\\\ndef add(\\\\n    a:int, # the 1st number to add\\\\n    b=0,   # the 2nd number to add\\\\n)->int:    # the result of adding `a` to `b`\\\\n    \\\"The sum of two numbers.\\\"\\\\n    return a+b\\\\n```\\\\n\\\\n __\\\\n\\\\n## Numpy docstring helper functions\\\\n\\\\n[`docments`](https://fastcore.fast.ai/docments.html#docments) also supports numpy-style docstrings, or a mix or numpy-style and docments parameter documentation. The functions in this section help get and parse this information.\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/docments.py#L26)\\\\n\\\\n### docstring\\\\n\\\\n>\\\\n```\\\\n>      docstring (sym)\\\\n```\\\\n\\\\n_Get docstring for`sym` for functions ad classes_\\\\n\\\\n```\\\\ntest_eq(docstring(add), \\\"The sum of two numbers.\\\")\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/docments.py#L34)\\\\n\\\\n### parse_docstring\\\\n\\\\n>\\\\n```\\\\n>      parse_docstring (sym)\\\\n```\\\\n\\\\n_Parse a numpy-style docstring in`sym`_\\\\n\\\\n```\\\\n# parse_docstring(add_np)\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/docments.py#L39)\\\\n\\\\n### isdataclass\\\\n\\\\n>\\\\n```\\\\n>      isdataclass (s)\\\\n```\\\\n\\\\n_Check if`s` is a dataclass but not a dataclass\\u2019 instance_\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/docments.py#L44)\\\\n\\\\n### get_dataclass_source\\\\n\\\\n>\\\\n```\\\\n>      get_dataclass_source (s)\\\\n```\\\\n\\\\n_Get source code for dataclass`s`_\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/docments.py#L49)\\\\n\\\\n### get_source\\\\n\\\\n>\\\\n```\\\\n>      get_source (s)\\\\n```\\\\n\\\\n_Get source code for string, function object or dataclass`s`_\\\\n\\\\n```\\\\nparms = _param_locs(add)\\\\nparms\\\\n```\\\\n\\\\n __\\\\n\\\\n```\\\\n{2: \\\\'a\\\\', 3: \\\\'b\\\\', 4: \\\\'return\\\\'}\\\\n```\\\\n\\\\n```\\\\n_get_comment(2, \\\\'a\\\\', {2: \\\\' the 1st number to add\\\\'}, parms)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n\\\\'the 1st number to add\\\\'\\\\n```\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/docments.py#L131)\\\\n\\\\n### get_name\\\\n\\\\n>\\\\n```\\\\n>      get_name (obj)\\\\n```\\\\n\\\\n_Get the name of`obj`_\\\\n\\\\n```\\\\ntest_eq(get_name(in_ipython), \\\\'in_ipython\\\\')\\\\ntest_eq(get_name(L.map), \\\\'map\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/docments.py#L140)\\\\n\\\\n### qual_name\\\\n\\\\n>\\\\n```\\\\n>      qual_name (obj)\\\\n```\\\\n\\\\n_Get the qualified name of`obj`_\\\\n\\\\n```\\\\nassert qual_name(docscrape) == \\\\'fastcore.docscrape\\\\'\\\\n```\\\\n\\\\n__\\\\n\\\\n## Docments\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/docments.py#L167)\\\\n\\\\n### docments\\\\n\\\\n>\\\\n```\\\\n>      docments (elt, full=False, args_kwargs=False, returns=True,\\\\n>                eval_str=False)\\\\n```\\\\n\\\\n_Generates a`docment`_\\\\n\\\\nThe returned `dict` has parameter names as keys, docments as values. The return value comment appears in the `return`, unless `returns=False`. Using the `add` definition above, we get:\\\\n\\\\n```\\\\ndef add(\\\\n    a:int, # the 1st number to add\\\\n    b=0,   # the 2nd number to add\\\\n)->int:    # the result of adding `a` to `b`\\\\n    \\\"The sum of two numbers.\\\"\\\\n    return a+b\\\\n\\\\ndocments(add)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n{ \\\\'a\\\\': \\\\'the 1st number to add\\\\',\\\\n  \\\\'b\\\\': \\\\'the 2nd number to add\\\\',\\\\n  \\\\'return\\\\': \\\\'the result of adding `a` to `b`\\\\'}\\\\n```\\\\n\\\\n__\\\\n\\\\n`args_kwargs=True` adds args and kwargs docs too:\\\\n\\\\n```\\\\ndef add(*args, # some args\\\\n    a:int, # the 1st number to add\\\\n    b=0,   # the 2nd number to add\\\\n    **kwargs, # Passed to the `example` function\\\\n)->int:    # the result of adding `a` to `b`\\\\n    \\\"The sum of two numbers.\\\"\\\\n    return a+b\\\\n\\\\ndocments(add, args_kwargs=True)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n{ \\\\'a\\\\': \\\\'the 1st number to add\\\\',\\\\n  \\\\'args\\\\': \\\\'some args\\\\',\\\\n  \\\\'b\\\\': \\\\'the 2nd number to add\\\\',\\\\n  \\\\'kwargs\\\\': None,\\\\n  \\\\'return\\\\': \\\\'the result of adding `a` to `b`\\\\'}\\\\n```\\\\n\\\\n__\\\\n\\\\nIf you pass `full=True`, the values are `dict` of defaults, types, and docments as values. Note that the type annotation is inferred from the default value, if the annotation is empty and a default is supplied. (Note that for `full`, `args_kwargs=True` is always set too.)\\\\n\\\\n```\\\\ndocments(add, full=True)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n{ \\\\'a\\\\': { \\\\'anno\\\\': <class \\\\'int\\\\'>,\\\\n         \\\\'default\\\\': <class \\\\'inspect._empty\\\\'>,\\\\n         \\\\'docment\\\\': \\\\'the 1st number to add\\\\'},\\\\n  \\\\'args\\\\': { \\\\'anno\\\\': <_ParameterKind.VAR_POSITIONAL: 2>,\\\\n            \\\\'default\\\\': <class \\\\'inspect._empty\\\\'>,\\\\n            \\\\'docment\\\\': \\\\'some args\\\\'},\\\\n  \\\\'b\\\\': { \\\\'anno\\\\': <class \\\\'int\\\\'>,\\\\n         \\\\'default\\\\': 0,\\\\n         \\\\'docment\\\\': \\\\'the 2nd number to add\\\\'},\\\\n  \\\\'kwargs\\\\': { \\\\'anno\\\\': <_ParameterKind.VAR_KEYWORD: 4>,\\\\n              \\\\'default\\\\': <class \\\\'inspect._empty\\\\'>,\\\\n              \\\\'docment\\\\': None},\\\\n  \\\\'return\\\\': { \\\\'anno\\\\': <class \\\\'int\\\\'>,\\\\n              \\\\'default\\\\': <class \\\\'inspect._empty\\\\'>,\\\\n              \\\\'docment\\\\': \\\\'the result of adding `a` to `b`\\\\'}}\\\\n```\\\\n\\\\n__\\\\n\\\\nTo evaluate stringified annotations (from python 3.10), use `eval_str`:\\\\n\\\\n```\\\\ndocments(add, full=True, eval_str=True)[\\\\'a\\\\']\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n{ \\\\'anno\\\\': <class \\\\'int\\\\'>,\\\\n  \\\\'default\\\\': <class \\\\'inspect._empty\\\\'>,\\\\n  \\\\'docment\\\\': \\\\'the 1st number to add\\\\'}\\\\n```\\\\n\\\\n__\\\\n\\\\nIf you need more space to document a parameter, place one or more lines of comments above the parameter, or above the return type. You can mix-and-match these docment styles:\\\\n\\\\n```\\\\ndef add(\\\\n    # The first operand\\\\n    a:int,\\\\n    # This is the second of the operands to the *addition* operator.\\\\n    # Note that passing a negative value here is the equivalent of the *subtraction* operator.\\\\n    b:int,\\\\n)->int: # The result is calculated using Python\\\\'s builtin `+` operator.\\\\n    \\\"Add `a` to `b`\\\"\\\\n    return a+b\\\\n```\\\\n\\\\n __\\\\n\\\\n```\\\\ndocments(add)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n{ \\\\'a\\\\': \\\\'The first operand\\\\',\\\\n  \\\\'b\\\\': \\\\'This is the second of the operands to the *addition* operator.\\\\\\\\n\\\\'\\\\n       \\\\'Note that passing a negative value here is the equivalent of the \\\\'\\\\n       \\\\'*subtraction* operator.\\\\',\\\\n  \\\\'return\\\\': \\\"The result is calculated using Python\\\\'s builtin `+` operator.\\\"}\\\\n```\\\\n\\\\n__\\\\n\\\\nDocments works with async functions, too:\\\\n\\\\n```\\\\nasync def add_async(\\\\n    # The first operand\\\\n    a:int,\\\\n    # This is the second of the operands to the *addition* operator.\\\\n    # Note that passing a negative value here is the equivalent of the *subtraction* operator.\\\\n    b:int,\\\\n)->int: # The result is calculated using Python\\\\'s builtin `+` operator.\\\\n    \\\"Add `a` to `b`\\\"\\\\n    return a+b\\\\n```\\\\n\\\\n __\\\\n\\\\n```\\\\ntest_eq(docments(add_async), docments(add))\\\\n```\\\\n\\\\n__\\\\n\\\\nYou can also use docments with classes and methods:\\\\n\\\\n```\\\\nclass Adder:\\\\n    \\\"An addition calculator\\\"\\\\n    def __init__(self,\\\\n        a:int, # First operand\\\\n        b:int, # 2nd operand\\\\n    ): self.a,self.b = a,b\\\\n\\\\n    def calculate(self\\\\n                 )->int: # Integral result of addition operator\\\\n        \\\"Add `a` to `b`\\\"\\\\n        return a+b\\\\n```\\\\n\\\\n __\\\\n\\\\n```\\\\ndocments(Adder)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n{\\\\'a\\\\': \\\\'First operand\\\\', \\\\'b\\\\': \\\\'2nd operand\\\\', \\\\'return\\\\': None}\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\ndocments(Adder.calculate)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n{\\\\'return\\\\': \\\\'Integral result of addition operator\\\\', \\\\'self\\\\': None}\\\\n```\\\\n\\\\n__\\\\n\\\\ndocments can also be extracted from numpy-style docstrings:\\\\n\\\\n```\\\\nprint(add_np.__doc__)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\nThe sum of two numbers.\\\\n\\\\n    Used to demonstrate numpy-style docstrings.\\\\n\\\\nParameters\\\\n----------\\\\na : int\\\\n    the 1st number to add\\\\nb : int\\\\n    the 2nd number to add (default: 0)\\\\n\\\\nReturns\\\\n-------\\\\nint\\\\n    the result of adding `a` to `b`\\\\n```\\\\n\\\\n```\\\\ndocments(add_np)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n{ \\\\'a\\\\': \\\\'the 1st number to add\\\\',\\\\n  \\\\'b\\\\': \\\\'the 2nd number to add (default: 0)\\\\',\\\\n  \\\\'return\\\\': \\\\'the result of adding `a` to `b`\\\\'}\\\\n```\\\\n\\\\n__\\\\n\\\\nYou can even mix and match docments and numpy parameters:\\\\n\\\\n```\\\\ndef add_mixed(a:int, # the first number to add\\\\n              b\\\\n             )->int: # the result\\\\n    \\\"\\\"\\\"The sum of two numbers.\\\\n\\\\nParameters\\\\n----------\\\\nb : int\\\\n    the 2nd number to add (default: 0)\\\"\\\"\\\"\\\\n    return a+b\\\\n```\\\\n\\\\n __\\\\n\\\\n```\\\\ndocments(add_mixed, full=True)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n{ \\\\'a\\\\': { \\\\'anno\\\\': <class \\\\'int\\\\'>,\\\\n         \\\\'default\\\\': <class \\\\'inspect._empty\\\\'>,\\\\n         \\\\'docment\\\\': \\\\'the first number to add\\\\'},\\\\n  \\\\'b\\\\': { \\\\'anno\\\\': \\\\'int\\\\',\\\\n         \\\\'default\\\\': <class \\\\'inspect._empty\\\\'>,\\\\n         \\\\'docment\\\\': \\\\'the 2nd number to add (default: 0)\\\\'},\\\\n  \\\\'return\\\\': { \\\\'anno\\\\': <class \\\\'int\\\\'>,\\\\n              \\\\'default\\\\': <class \\\\'inspect._empty\\\\'>,\\\\n              \\\\'docment\\\\': \\\\'the result\\\\'}}\\\\n```\\\\n\\\\n__\\\\n\\\\nYou can use docments with dataclasses, however if the class was defined in online notebook, docments will not contain parameters\\u2019 comments. This is because the source code is not available in the notebook. After converting the notebook to a module, the docments will be available. Thus, documentation will have correct parameters\\u2019 comments.\\\\n\\\\nDocments even works with [`delegates`](https://fastcore.fast.ai/meta.html#delegates):\\\\n\\\\n```\\\\nfrom fastcore.meta import delegates\\\\n```\\\\n\\\\n __\\\\n\\\\n```\\\\ndef _a(a:int=2): return a # First\\\\n\\\\n@delegates(_a)\\\\ndef _b(b:str, # Second\\\\n       **kwargs\\\\n      ): # Return nothing\\\\n    return b, (_a(**kwargs)) \\\\n\\\\ndocments(_b)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n{\\\\'a\\\\': \\\\'First\\\\', \\\\'b\\\\': \\\\'Second\\\\', \\\\'return\\\\': None}\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\ndocments(_b, full=True)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n{ \\\\'a\\\\': {\\\\'anno\\\\': <class \\\\'int\\\\'>, \\\\'default\\\\': 2, \\\\'docment\\\\': \\\\'First\\\\'},\\\\n  \\\\'b\\\\': { \\\\'anno\\\\': \\\\'str\\\\',\\\\n         \\\\'default\\\\': <class \\\\'inspect._empty\\\\'>,\\\\n         \\\\'docment\\\\': \\\\'Second\\\\'},\\\\n  \\\\'return\\\\': { \\\\'anno\\\\': <class \\\\'inspect._empty\\\\'>,\\\\n              \\\\'default\\\\': <class \\\\'inspect._empty\\\\'>,\\\\n              \\\\'docment\\\\': None}}\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/docments.py#L184)\\\\n\\\\n### sig2str\\\\n\\\\n>\\\\n```\\\\n>      sig2str (func)\\\\n```\\\\n\\\\n_Generate function signature with docments as comments_\\\\n\\\\n```\\\\nprint(sig2str(_d))\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\ndef _d(\\\\n    b:str # Second,\\\\n    a:int=2 # Third,\\\\n    c:int # First\\\\n)->int: # Return an int\\\\n\\\\n```\\\\n\\\\n## Extract docstrings\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/docments.py#L245)\\\\n\\\\n### extract_docstrings\\\\n\\\\n>\\\\n```\\\\n>      extract_docstrings (code)\\\\n```\\\\n\\\\n_Create a dict from function/class/method names to tuples of docstrings and param lists_\\\\n\\\\n```\\\\nsample_code = \\\"\\\"\\\"\\\\n\\\"This is a module.\\\"\\\\n\\\\ndef top_func(a, b, *args, **kw):\\\\n    \\\"This is top-level.\\\"\\\\n    pass\\\\n\\\\nclass SampleClass:\\\\n    \\\"This is a class.\\\"\\\\n\\\\n    def __init__(self, x, y):\\\\n        \\\"Constructor for SampleClass.\\\"\\\\n        pass\\\\n\\\\n    def method1(self, param1):\\\\n        \\\"This is method1.\\\"\\\\n        pass\\\\n\\\\n    def _private_method(self):\\\\n        \\\"This should not be included.\\\"\\\\n        pass\\\\n\\\\nclass AnotherClass:\\\\n    def __init__(self, a, b):\\\\n        \\\"This class has no separate docstring.\\\"\\\\n        pass\\\"\\\"\\\"\\\\n\\\\nexp = {\\\\'_module\\\\': (\\\\'This is a module.\\\\', \\\\'\\\\'),\\\\n       \\\\'top_func\\\\': (\\\\'This is top-level.\\\\', \\\\'a, b, *args, **kw\\\\'),\\\\n       \\\\'SampleClass\\\\': (\\\\'This is a class.\\\\', \\\\'self, x, y\\\\'),\\\\n       \\\\'SampleClass.method1\\\\': (\\\\'This is method1.\\\\', \\\\'self, param1\\\\'),\\\\n       \\\\'AnotherClass\\\\': (\\\\'This class has no separate docstring.\\\\', \\\\'self, a, b\\\\')}\\\\ntest_eq(extract_docstrings(sample_code), exp)\\\\n```\\\\n\\\\n__\\\\n\\\\n  * [__Report an issue](https://github.com/AnswerDotAI/fastcore/issues/new)'\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_016PG8FSvpSa3RFBF3KC4n4V\",\n",
    "  \"call\": {\n",
    "    \"function\": \"read_url\",\n",
    "    \"arguments\": {\n",
    "      \"url\": \"https://fastcore.fast.ai/meta.html\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'[ ](./index.html) [ fastcore ](./index.html)\\\\n\\\\n  * [ __ ](https://github.com/fastai/fastcore)\\\\n  * [ __ ](https://x.com/fastdotai)\\\\n\\\\n__\\\\n\\\\n  1. [Meta](./meta.html)\\\\n\\\\n[ ](./index.html)\\\\n\\\\n  * [ Welcome to fastcore](./index.html)\\\\n\\\\n  * [ A tour of fastcore](./tour.html)\\\\n\\\\n  * [ Test](./test.html)\\\\n\\\\n  * [ Basic functionality](./basics.html)\\\\n\\\\n  * [ Foundation](./foundation.html)\\\\n\\\\n  * [ Utility functions](./xtras.html)\\\\n\\\\n  * [ Parallel](./parallel.html)\\\\n\\\\n  * [ Network functionality](./net.html)\\\\n\\\\n  * [ Docments](./docments.html)\\\\n\\\\n  * [ Meta](./meta.html)\\\\n\\\\n  * [ Script - CLI](./script.html)\\\\n\\\\n  * [ XDG](./xdg.html)\\\\n\\\\n  * [ Style](./style.html)\\\\n\\\\n  * [ XML](./xml.html)\\\\n\\\\n  * [ Create delegated pyi](./py2pyi.html)\\\\n\\\\n  * [ External modules](./external.html)\\\\n\\\\n  * [ LLM tools](./tools.html)\\\\n\\\\n## On this page\\\\n\\\\n  * test_sig\\\\n  * FixSigMeta\\\\n  * PrePostInitMeta\\\\n  * AutoInit\\\\n  * NewChkMeta\\\\n  * BypassNewMeta\\\\n  * Metaprogramming\\\\n    * empty2none\\\\n    * anno_dict\\\\n    * use_kwargs_dict\\\\n    * use_kwargs\\\\n    * delegates\\\\n    * method\\\\n    * funcs_kwargs\\\\n\\\\n  * [__Report an issue](https://github.com/AnswerDotAI/fastcore/issues/new)\\\\n\\\\n## Other Formats\\\\n\\\\n  * [ __CommonMark](meta.html.md)\\\\n\\\\n# Meta\\\\n\\\\nMetaclasses\\\\n\\\\n```\\\\nfrom fastcore.foundation import *\\\\nfrom nbdev.showdoc import *\\\\nfrom fastcore.nb_imports import *\\\\n```\\\\n\\\\n__\\\\n\\\\nSee this [blog post](https://realpython.com/python-metaclasses/) for more information about metaclasses.\\\\n\\\\n  * [`FixSigMeta`](https://fastcore.fast.ai/meta.html#fixsigmeta) preserves information that enables [intropsection of signatures](https://www.python.org/dev/peps/pep-0362/#:~:text=Python%20has%20always%20supported%20powerful,fully%20reconstruct%20the%20function\\\\'s%20signature.) (i.e. tab completion in IDEs) when certain types of inheritence would otherwise obfuscate this introspection.\\\\n  * [`PrePostInitMeta`](https://fastcore.fast.ai/meta.html#prepostinitmeta) ensures that the classes defined with it run `__pre_init__` and `__post_init__` (without having to write `self.__pre_init__()` and `self.__post_init__()` in the actual `init`\\\\n  * [`NewChkMeta`](https://fastcore.fast.ai/meta.html#newchkmeta) gives the [`PrePostInitMeta`](https://fastcore.fast.ai/meta.html#prepostinitmeta) functionality and ensures classes defined with it don\\u2019t re-create an object of their type whenever it\\u2019s passed to the constructor\\\\n  * [`BypassNewMeta`](https://fastcore.fast.ai/meta.html#bypassnewmeta) ensures classes defined with it can easily be casted form objects they subclass.\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L17)\\\\n\\\\n### test_sig\\\\n\\\\n>\\\\n```\\\\n>      test_sig (f, b)\\\\n```\\\\n\\\\n_Test the signature of an object_\\\\n\\\\n```\\\\ndef func_1(h,i,j): pass\\\\ndef func_2(h,i=3, j=[5,6]): pass\\\\n\\\\nclass T:\\\\n    def __init__(self, a, b): pass\\\\n\\\\ntest_sig(func_1, \\\\'(h, i, j)\\\\')\\\\ntest_sig(func_2, \\\\'(h, i=3, j=[5, 6])\\\\')\\\\ntest_sig(T, \\\\'(a, b)\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L28)\\\\n\\\\n### FixSigMeta\\\\n\\\\n>\\\\n```\\\\n>      FixSigMeta (name, bases, dict)\\\\n```\\\\n\\\\n_A metaclass that fixes the signature on classes that override`__new__`_\\\\n\\\\nWhen you inherit from a class that defines `__new__`, or a metaclass that defines `__call__`, the signature of your `__init__` method is obfuscated such that tab completion no longer works. [`FixSigMeta`](https://fastcore.fast.ai/meta.html#fixsigmeta) fixes this issue and restores signatures.\\\\n\\\\nTo understand what [`FixSigMeta`](https://fastcore.fast.ai/meta.html#fixsigmeta) does, it is useful to inspect an object\\u2019s signature. You can inspect the signature of an object with `inspect.signature`:\\\\n\\\\n```\\\\nclass T:\\\\n    def __init__(self, a, b, c): pass\\\\n\\\\ninspect.signature(T)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n<Signature (a, b, c)>\\\\n```\\\\n\\\\nThis corresponds to tab completion working in the normal way:\\\\n\\\\n![Tab completion in a Jupyter Notebook.](images/att_00005.png)\\\\n\\\\nHowever, when you inherhit from a class that defines `__new__` or a metaclass that defines `__call__` this obfuscates the signature by overriding your class with the signature of `__new__`, which prevents tab completion from displaying useful information:\\\\n\\\\n```\\\\nclass Foo:\\\\n    def __new__(self, **args): pass\\\\n\\\\nclass Bar(Foo):\\\\n    def __init__(self, d, e, f): pass\\\\n\\\\ninspect.signature(Bar)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n<Signature (d, e, f)>\\\\n```\\\\n\\\\n![Tab completion in a Jupyter Notebook.](images/att_00006.png)\\\\n\\\\nFinally, the signature and tab completion can be restored by inheriting from the metaclass [`FixSigMeta`](https://fastcore.fast.ai/meta.html#fixsigmeta) as shown below:\\\\n\\\\n```\\\\nclass Bar(Foo, metaclass=FixSigMeta):\\\\n    def __init__(self, d, e, f): pass\\\\n\\\\ntest_sig(Bar, \\\\'(d, e, f)\\\\')\\\\ninspect.signature(Bar)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n<Signature (d, e, f)>\\\\n```\\\\n\\\\n![Tab completion in a Jupyter Notebook.](images/att_00007.png)\\\\n\\\\nIf you need to define a metaclass that overrides `__call__` (as done in [`PrePostInitMeta`](https://fastcore.fast.ai/meta.html#prepostinitmeta)), you need to inherit from [`FixSigMeta`](https://fastcore.fast.ai/meta.html#fixsigmeta) instead of `type` when constructing the metaclass to preserve the signature in `__init__`. Be careful not to override `__new__` when doing this:\\\\n\\\\n```\\\\nclass TestMeta(FixSigMeta):\\\\n    # __new__ comes from FixSigMeta\\\\n    def __call__(cls, *args, **kwargs): pass\\\\n\\\\nclass T(metaclass=TestMeta):\\\\n    def __init__(self, a, b): pass\\\\n\\\\ntest_sig(T, \\\\'(a, b)\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\nOn the other hand, if you fail to inherit from [`FixSigMeta`](https://fastcore.fast.ai/meta.html#fixsigmeta) when inheriting from a metaclass that overrides `__call__`, your signature will reflect that of `__call__` instead (which is often undesirable):\\\\n\\\\n```\\\\nclass GenericMeta(type):\\\\n    \\\"A boilerplate metaclass that doesn\\\\'t do anything for testing.\\\"\\\\n    def __new__(cls, name, bases, dict):\\\\n        return super().__new__(cls, name, bases, dict)\\\\n    def __call__(cls, *args, **kwargs): pass\\\\n\\\\nclass T2(metaclass=GenericMeta):\\\\n    def __init__(self, a, b): pass\\\\n\\\\n# We can avoid this by inheriting from the metaclass `FixSigMeta`\\\\ntest_sig(T2, \\\\'(*args, **kwargs)\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L36)\\\\n\\\\n### PrePostInitMeta\\\\n\\\\n>\\\\n```\\\\n>      PrePostInitMeta (name, bases, dict)\\\\n```\\\\n\\\\n_A metaclass that calls optional`__pre_init__` and `__post_init__` methods_\\\\n\\\\n`__pre_init__` and `__post_init__` are useful for initializing variables or performing tasks prior to or after `__init__` being called, respectively. Fore example:\\\\n\\\\n```\\\\nclass _T(metaclass=PrePostInitMeta):\\\\n    def __pre_init__(self):  self.a  = 0; \\\\n    def __init__(self,b=0):  self.b = self.a + 1; assert self.b==1\\\\n    def __post_init__(self): self.c = self.b + 2; assert self.c==3\\\\n\\\\nt = _T()\\\\ntest_eq(t.a, 0) # set with __pre_init__\\\\ntest_eq(t.b, 1) # set with __init__\\\\ntest_eq(t.c, 3) # set with __post_init__\\\\n```\\\\n\\\\n__\\\\n\\\\nOne use for [`PrePostInitMeta`](https://fastcore.fast.ai/meta.html#prepostinitmeta) is avoiding the `__super__().__init__()` boilerplate associated with subclassing, such as used in [`AutoInit`](https://fastcore.fast.ai/meta.html#autoinit).\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L47)\\\\n\\\\n### AutoInit\\\\n\\\\n>\\\\n```\\\\n>      AutoInit (*args, **kwargs)\\\\n```\\\\n\\\\n_Same as`object`, but no need for subclasses to call `super().__init__`_\\\\n\\\\nThis is normally used as a [mixin](https://www.residentmar.io/2019/07/07/python-mixins.html), eg:\\\\n\\\\n```\\\\nclass TestParent():\\\\n    def __init__(self): self.h = 10\\\\n\\\\nclass TestChild(AutoInit, TestParent):\\\\n    def __init__(self): self.k = self.h + 2\\\\n\\\\nt = TestChild()\\\\ntest_eq(t.h, 10) # h=10 is initialized in the parent class\\\\ntest_eq(t.k, 12)\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L52)\\\\n\\\\n### NewChkMeta\\\\n\\\\n>\\\\n```\\\\n>      NewChkMeta (name, bases, dict)\\\\n```\\\\n\\\\n_Metaclass to avoid recreating object passed to constructor_\\\\n\\\\n[`NewChkMeta`](https://fastcore.fast.ai/meta.html#newchkmeta) is used when an object of the same type is the first argument to your class\\u2019s constructor (i.e. the `__init__` function), and you would rather it not create a new object but point to the same exact object.\\\\n\\\\nThis is used in [`L`](https://fastcore.fast.ai/foundation.html#l), for example, to avoid creating a new object when the object is already of type [`L`](https://fastcore.fast.ai/foundation.html#l). This allows the users to defenisvely instantiate an [`L`](https://fastcore.fast.ai/foundation.html#l) object and just return a reference to the same object if it already happens to be of type [`L`](https://fastcore.fast.ai/foundation.html#l).\\\\n\\\\nFor example, the below class `_T` **optionally** accepts an object `o` as its first argument. A new object is returned upon instantiation per usual:\\\\n\\\\n```\\\\nclass _T():\\\\n    \\\"Testing\\\"\\\\n    def __init__(self, o): \\\\n        # if `o` is not an object without an attribute `foo`, set foo = 1\\\\n        self.foo = getattr(o,\\\\'foo\\\\',1)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\nt = _T(3)\\\\ntest_eq(t.foo,1) # 1 was not of type _T, so foo = 1\\\\n\\\\nt2 = _T(t) #t1 is of type _T\\\\nassert t is not t2 # t1 and t2 are different objects\\\\n```\\\\n\\\\n __\\\\n\\\\nHowever, if we want `_T` to return a reference to the same object when passed an an object of type `_T` we can inherit from the [`NewChkMeta`](https://fastcore.fast.ai/meta.html#newchkmeta) class as illustrated below:\\\\n\\\\n```\\\\nclass _T(metaclass=NewChkMeta):\\\\n    \\\"Testing with metaclass NewChkMeta\\\"\\\\n    def __init__(self, o=None, b=1):\\\\n        # if `o` is not an object without an attribute `foo`, set foo = 1\\\\n        self.foo = getattr(o,\\\\'foo\\\\',1)\\\\n        self.b = b\\\\n```\\\\n\\\\n __\\\\n\\\\nWe can now test `t` and `t2` are now pointing at the same object when using this new definition of `_T`:\\\\n\\\\n```\\\\nt = _T(3)\\\\ntest_eq(t.foo,1) # 1 was not of type _T, so foo = 1\\\\n\\\\nt2 = _T(t) # t2 will now reference t\\\\n\\\\ntest_is(t, t2) # t and t2 are the same object\\\\nt2.foo = 5 # this will also change t.foo to 5 because it is the same object\\\\ntest_eq(t.foo, 5)\\\\ntest_eq(t2.foo, 5)\\\\n```\\\\n\\\\n__\\\\n\\\\nHowever, there is one exception to how [`NewChkMeta`](https://fastcore.fast.ai/meta.html#newchkmeta) works. **If you pass any additional arguments in the constructor a new object is returned** , even if the first object is of the same type. For example, consider the below example where we pass the additional argument `b` into the constructor:\\\\n\\\\n```\\\\nt3 = _T(t, b=1)\\\\nassert t3 is not t\\\\n\\\\nt4 = _T(t) # without any arguments the constructor will return a reference to the same object\\\\nassert t4 is t\\\\n```\\\\n\\\\n __\\\\n\\\\nFinally, it should be noted that [`NewChkMeta`](https://fastcore.fast.ai/meta.html#newchkmeta) as well as all other metaclases in this section, inherit from [`FixSigMeta`](https://fastcore.fast.ai/meta.html#fixsigmeta). This means class signatures will always be preserved when inheriting from this metaclass (see docs for [`FixSigMeta`](https://fastcore.fast.ai/meta.html#fixsigmeta) for more details):\\\\n\\\\n```\\\\ntest_sig(_T, \\\\'(o=None, b=1)\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L60)\\\\n\\\\n### BypassNewMeta\\\\n\\\\n>\\\\n```\\\\n>      BypassNewMeta (name, bases, dict)\\\\n```\\\\n\\\\n_Metaclass: casts`x` to this class if it\\u2019s of type `cls._bypass_type`_\\\\n\\\\n[`BypassNewMeta`](https://fastcore.fast.ai/meta.html#bypassnewmeta) is identical to [`NewChkMeta`](https://fastcore.fast.ai/meta.html#newchkmeta), except for checking for a class as the same type, we instead check for a class of type specified in attribute `_bypass_type`.\\\\n\\\\nIn NewChkMeta, objects of the same type passed to the constructor (without arguments) would result into a new variable referencing the same object. However, with [`BypassNewMeta`](https://fastcore.fast.ai/meta.html#bypassnewmeta) this only occurs if the type matches the `_bypass_type` of the class you are defining:\\\\n\\\\n```\\\\nclass _TestA: pass\\\\nclass _TestB: pass\\\\n\\\\nclass _T(_TestA, metaclass=BypassNewMeta):\\\\n    _bypass_type=_TestB\\\\n    def __init__(self,x): self.x=x\\\\n```\\\\n\\\\n __\\\\n\\\\nIn the below example, `t` does not refer to `t2` because `t` is of type `_TestA` while `_T._bypass_type` is of type `TestB`:\\\\n\\\\n```\\\\nt = _TestA()\\\\nt2 = _T(t)\\\\nassert t is not t2\\\\n```\\\\n\\\\n __\\\\n\\\\nHowever, if `t` is set to `_TestB` to match `_T._bypass_type`, then both `t` and `t2` will refer to the same object.\\\\n\\\\n```\\\\nt = _TestB()\\\\nt2 = _T(t)\\\\nt2.new_attr = 15\\\\n\\\\ntest_is(t, t2)\\\\n# since t2 just references t these will be the same\\\\ntest_eq(t.new_attr, t2.new_attr)\\\\n\\\\n# likewise, chaning an attribute on t will also affect t2 because they both point to the same object.\\\\nt.new_attr = 9\\\\ntest_eq(t2.new_attr, 9)\\\\n```\\\\n\\\\n__\\\\n\\\\n## Metaprogramming\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L70)\\\\n\\\\n### empty2none\\\\n\\\\n>\\\\n```\\\\n>      empty2none (p)\\\\n```\\\\n\\\\n_Replace`Parameter.empty` with `None`_\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L75)\\\\n\\\\n### anno_dict\\\\n\\\\n>\\\\n```\\\\n>      anno_dict (f)\\\\n```\\\\n\\\\n_`__annotation__ dictionary with`empty`cast to`None`, returning empty if doesn\\u2019t exist_\\\\n\\\\n```\\\\ndef _f(a:int, b:L)->str: ...\\\\ntest_eq(anno_dict(_f), {\\\\'a\\\\': int, \\\\'b\\\\': L, \\\\'return\\\\': str})\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L83)\\\\n\\\\n### use_kwargs_dict\\\\n\\\\n>\\\\n```\\\\n>      use_kwargs_dict (keep=False, **kwargs)\\\\n```\\\\n\\\\n_Decorator: replace`**kwargs` in signature with `names` params_\\\\n\\\\nReplace all `**kwargs` with named arguments like so:\\\\n\\\\n```\\\\n@use_kwargs_dict(y=1,z=None)\\\\ndef foo(a, b=1, **kwargs): pass\\\\n\\\\ntest_sig(foo, \\\\'(a, b=1, *, y=1, z=None)\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\nAdd named arguments, but optionally keep `**kwargs` by setting `keep=True`:\\\\n\\\\n```\\\\n@use_kwargs_dict(y=1,z=None, keep=True)\\\\ndef foo(a, b=1, **kwargs): pass\\\\n\\\\ntest_sig(foo, \\\\'(a, b=1, *, y=1, z=None, **kwargs)\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L97)\\\\n\\\\n### use_kwargs\\\\n\\\\n>\\\\n```\\\\n>      use_kwargs (names, keep=False)\\\\n```\\\\n\\\\n_Decorator: replace`**kwargs` in signature with `names` params_\\\\n\\\\n[`use_kwargs`](https://fastcore.fast.ai/meta.html#use_kwargs) is different than [`use_kwargs_dict`](https://fastcore.fast.ai/meta.html#use_kwargs_dict) as it only replaces `**kwargs` with named parameters without any default values:\\\\n\\\\n```\\\\n@use_kwargs([\\\\'y\\\\', \\\\'z\\\\'])\\\\ndef foo(a, b=1, **kwargs): pass\\\\n\\\\ntest_sig(foo, \\\\'(a, b=1, *, y=None, z=None)\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\nYou may optionally keep the `**kwargs` argument in your signature by setting `keep=True`:\\\\n\\\\n```\\\\n@use_kwargs([\\\\'y\\\\', \\\\'z\\\\'], keep=True)\\\\ndef foo(a, *args, b=1, **kwargs): pass\\\\ntest_sig(foo, \\\\'(a, *args, b=1, y=None, z=None, **kwargs)\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L111)\\\\n\\\\n### delegates\\\\n\\\\n>\\\\n```\\\\n>      delegates (to:function=None, keep=False, but:list=None, sort_args=False)\\\\n```\\\\n\\\\n_Decorator: replace`**kwargs` in signature with params from `to`_\\\\n\\\\n| **Type** | **Default** | **Details**  \\\\n---|---|---|---  \\\\nto | function | None | Delegatee  \\\\nkeep | bool | False | Keep `kwargs` in decorated function?  \\\\nbut | list | None | Exclude these parameters from signature  \\\\nsort_args | bool | False | Sort arguments alphabetically, doesn\\u2019t work with call_parse  \\\\n  \\\\nA common Python idiom is to accept `**kwargs` in addition to named parameters that are passed onto other function calls. It is especially common to use `**kwargs` when you want to give the user an option to override default parameters of any functions or methods being called by the parent function.\\\\n\\\\nFor example, suppose we have have a function `foo` that passes arguments to `baz` like so:\\\\n\\\\n```\\\\ndef baz(a, b:int=2, c:int=3): return a + b + c\\\\n\\\\ndef foo(c, a, **kwargs):\\\\n    return c + baz(a, **kwargs)\\\\n\\\\nassert foo(c=1, a=1) == 7\\\\n```\\\\n\\\\n __\\\\n\\\\nThe problem with this approach is the api for `foo` is obfuscated. Users cannot introspect what the valid arguments for `**kwargs` are without reading the source code. When a user tries tries to introspect the signature of `foo`, they are presented with this:\\\\n\\\\n```\\\\ninspect.signature(foo)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n<Signature (c, a, **kwargs)>\\\\n```\\\\n\\\\nWe can address this issue by using the decorator [`delegates`](https://fastcore.fast.ai/meta.html#delegates) to include parameters from other functions. For example, if we apply the [`delegates`](https://fastcore.fast.ai/meta.html#delegates) decorator to `foo` to include parameters from `baz`:\\\\n\\\\n```\\\\n@delegates(baz)\\\\ndef foo(c, a, **kwargs):\\\\n    return c + baz(a, **kwargs)\\\\n\\\\ntest_sig(foo, \\\\'(c, a, *, b: int = 2)\\\\')\\\\ninspect.signature(foo)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n<Signature (c, a, *, b: int = 2)>\\\\n```\\\\n\\\\nWe can optionally decide to keep `**kwargs` by setting `keep=True`:\\\\n\\\\n```\\\\n@delegates(baz, keep=True)\\\\ndef foo(c, a, **kwargs):\\\\n    return c + baz(a, **kwargs)\\\\n\\\\ninspect.signature(foo)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n<Signature (c, a, *, b: int = 2, **kwargs)>\\\\n```\\\\n\\\\nIt is important to note that **only parameters with default parameters are included**. For example, in the below scenario only `c`, but NOT `e` and `d` are included in the signature of `foo` after applying [`delegates`](https://fastcore.fast.ai/meta.html#delegates):\\\\n\\\\n```\\\\ndef basefoo(e, d, c=2): pass\\\\n\\\\n@delegates(basefoo)\\\\ndef foo(a, b=1, **kwargs): pass\\\\ninspect.signature(foo) # e and d are not included b/c they don\\\\'t have default parameters.\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n<Signature (a, b=1, *, c=2)>\\\\n```\\\\n\\\\nThe reason that required arguments (i.e. those without default parameters) are automatically excluded is that you should be explicitly implementing required arguments into your function\\u2019s signature rather than relying on [`delegates`](https://fastcore.fast.ai/meta.html#delegates).\\\\n\\\\nAdditionally, you can exclude specific parameters from being included in the signature with the `but` parameter. In the example below, we exclude the parameter `d`:\\\\n\\\\n```\\\\ndef basefoo(e, c=2, d=3): pass\\\\n\\\\n@delegates(basefoo, but= [\\\\'d\\\\'])\\\\ndef foo(a, b=1, **kwargs): pass\\\\n\\\\ntest_sig(foo, \\\\'(a, b=1, *, c=2)\\\\')\\\\ninspect.signature(foo)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n<Signature (a, b=1, *, c=2)>\\\\n```\\\\n\\\\nYou can also use [`delegates`](https://fastcore.fast.ai/meta.html#delegates) between methods in a class. Here is an example of [`delegates`](https://fastcore.fast.ai/meta.html#delegates) with class methods:\\\\n\\\\n```\\\\n# example 1: class methods\\\\nclass _T():\\\\n    @classmethod\\\\n    def foo(cls, a=1, b=2):\\\\n        pass\\\\n\\\\n    @classmethod\\\\n    @delegates(foo)\\\\n    def bar(cls, c=3, **kwargs):\\\\n        pass\\\\n\\\\ntest_sig(_T.bar, \\\\'(c=3, *, a=1, b=2)\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\nHere is the same example with instance methods:\\\\n\\\\n```\\\\n# example 2: instance methods\\\\nclass _T():\\\\n    def foo(self, a=1, b=2):\\\\n        pass\\\\n\\\\n    @delegates(foo)\\\\n    def bar(self, c=3, **kwargs):\\\\n        pass\\\\n\\\\nt = _T()\\\\ntest_sig(t.bar, \\\\'(c=3, *, a=1, b=2)\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\nYou can also delegate between classes. By default, the [`delegates`](https://fastcore.fast.ai/meta.html#delegates) decorator will delegate to the superclass:\\\\n\\\\n```\\\\nclass BaseFoo:\\\\n    def __init__(self, e, c=2): pass\\\\n\\\\n@delegates()# since no argument was passsed here we delegate to the superclass\\\\nclass Foo(BaseFoo):\\\\n    def __init__(self, a, b=1, **kwargs): super().__init__(**kwargs)\\\\n\\\\ntest_sig(Foo, \\\\'(a, b=1, *, c=2)\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/meta.py#L139)\\\\n\\\\n### method\\\\n\\\\n>\\\\n```\\\\n>      method (f)\\\\n```\\\\n\\\\n_Mark`f` as a method_\\\\n\\\\nThe [`method`](https://fastcore.fast.ai/meta.html#method) function is used to change a function\\u2019s type to a method. In the below example we change the type of `a` from a function to a method:\\\\n\\\\n```\\\\ndef a(x=2): return x + 1\\\\nassert type(a).__name__ == \\\\'function\\\\'\\\\n\\\\na = method(a)\\\\nassert type(a).__name__ == \\\\'method\\\\'\\\\n```\\\\n\\\\n__\\\\n\\\\nYou can also s<TRUNCATED>\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01Lc8b7BKxJFgQtQmEyH75iA\",\n",
    "  \"call\": {\n",
    "    \"function\": \"read_url\",\n",
    "    \"arguments\": {\n",
    "      \"url\": \"https://fastcore.fast.ai/tools.html\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'[ ](./index.html) [ fastcore ](./index.html)\\\\n\\\\n  * [ __ ](https://github.com/fastai/fastcore)\\\\n  * [ __ ](https://x.com/fastdotai)\\\\n\\\\n__\\\\n\\\\n  1. [LLM tools](./tools.html)\\\\n\\\\n[ ](./index.html)\\\\n\\\\n  * [ Welcome to fastcore](./index.html)\\\\n\\\\n  * [ A tour of fastcore](./tour.html)\\\\n\\\\n  * [ Test](./test.html)\\\\n\\\\n  * [ Basic functionality](./basics.html)\\\\n\\\\n  * [ Foundation](./foundation.html)\\\\n\\\\n  * [ Utility functions](./xtras.html)\\\\n\\\\n  * [ Parallel](./parallel.html)\\\\n\\\\n  * [ Network functionality](./net.html)\\\\n\\\\n  * [ Docments](./docments.html)\\\\n\\\\n  * [ Meta](./meta.html)\\\\n\\\\n  * [ Script - CLI](./script.html)\\\\n\\\\n  * [ XDG](./xdg.html)\\\\n\\\\n  * [ Style](./style.html)\\\\n\\\\n  * [ XML](./xml.html)\\\\n\\\\n  * [ Create delegated pyi](./py2pyi.html)\\\\n\\\\n  * [ External modules](./external.html)\\\\n\\\\n  * [ LLM tools](./tools.html)\\\\n\\\\n## On this page\\\\n\\\\n  * Bash Tools\\\\n    * run_cmd\\\\n    * rg\\\\n    * sed\\\\n  * Text Edit Tools\\\\n    * view\\\\n    * create\\\\n    * insert\\\\n    * str_replace\\\\n    * strs_replace\\\\n    * replace_lines\\\\n\\\\n  * [__Report an issue](https://github.com/AnswerDotAI/fastcore/issues/new)\\\\n\\\\n## Other Formats\\\\n\\\\n  * [ __CommonMark](tools.html.md)\\\\n\\\\n# LLM tools\\\\n\\\\nHelpful tools for running cli commands and reading, modifying, and creating files in python. This is used primarily for AI\\u2019s in tool loops for automating tasks involving the filesystem.\\\\n\\\\n## Bash Tools\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/tools.py#L14)\\\\n\\\\n### run_cmd\\\\n\\\\n>\\\\n```\\\\n>      run_cmd (cmd:str, argstr:str=\\\\'\\\\', disallow_re:str=None, allow_re:str=None)\\\\n```\\\\n\\\\n_Run`cmd` passing split `argstr`, optionally checking for allowed argstr_\\\\n\\\\n| **Type** | **Default** | **Details**  \\\\n---|---|---|---  \\\\ncmd | str |  | The command name to run  \\\\nargstr | str |  | All args to the command, will be split with shlex  \\\\ndisallow_re | str | None | optional regex which, if matched on argstr, will disallow the command  \\\\nallow_re | str | None | optional regex which, if not matched on argstr, will disallow the command  \\\\n  \\\\nWith this little function, we can now run any cli command:\\\\n\\\\n```\\\\nprint(run_cmd(\\\\'ls\\\\')[:128])\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n000_tour.ipynb\\\\n00_test.ipynb\\\\n01_basics.ipynb\\\\n02_foundation.ipynb\\\\n03_xtras.ipynb\\\\n03a_parallel.ipynb\\\\n03b_net.ipynb\\\\n04_docments.ipy\\\\n```\\\\n\\\\nNote that, for tool safety, this is not passed through the shell, so wildcards, env vars, etc will not work:\\\\n\\\\n```\\\\nprint(run_cmd(\\\\'ls\\\\', \\\\'f*\\\\')[:128])\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\nls: f*: No such file or directory\\\\n\\\\n```\\\\n\\\\nLet\\u2019s create some useful functions from this that will allow for searching, reading and modifing content on the file system.\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/tools.py#L30)\\\\n\\\\n### rg\\\\n\\\\n>\\\\n```\\\\n>      rg (argstr:str, disallow_re:str=None, allow_re:str=None)\\\\n```\\\\n\\\\n_Run the[`rg`](https://fastcore.fast.ai/tools.html#rg) command with the args in `argstr` (no need to backslash escape)_\\\\n\\\\n| **Type** | **Default** | **Details**  \\\\n---|---|---|---  \\\\nargstr | str |  | All args to the command, will be split with shlex  \\\\ndisallow_re | str | None | optional regex which, if matched on argstr, will disallow the command  \\\\nallow_re | str | None | optional regex which, if not matched on argstr, will disallow the command\\\\n```\\\\nrg(\\\\'fast.ai CNAME\\\\')\\\\n```  \\\\n  \\\\n__\\\\n\\\\n```\\\\n\\\\'1:fastcore.fast.ai\\\\\\\\n\\\\'\\\\n```\\\\n\\\\nFunctions implemented with [`run_cmd`](https://fastcore.fast.ai/tools.html#run_cmd) like this one can be passed regexps to allow or disallow arg strs, i.e to block parent or root directories:\\\\n\\\\n```\\\\ndisallowed = r\\\\' /|\\\\\\\\.\\\\\\\\.\\\\'\\\\nrg(\\\\'[[email\\\\xa0protected]](/cdn-cgi/l/email-protection) ..\\\\', disallow_re=disallowed)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n\\\\'Error: args disallowed\\\\'\\\\n```\\\\n\\\\n```\\\\nrg(\\\\'[[email\\\\xa0protected]](/cdn-cgi/l/email-protection) /\\\\', disallow_re=disallowed)\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n\\\\'Error: args disallowed\\\\'\\\\n```\\\\n\\\\n```\\\\nprint(rg(\\\\'fast.ai CNAME\\\\', disallow_re=disallowed))\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n1:fastcore.fast.ai\\\\n\\\\n```\\\\n\\\\nNB: These tools have special behavior around errors. Since these have been speficially designed for work with LLMs, any exceptions created from there use is returned as a string to help them debug their work.\\\\n\\\\n```\\\\nrun_cmd(\\\\'asdfe\\\\')\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n\\\"Error running cmd: [Errno 2] No such file or directory: \\\\'asdfe\\\\'\\\"\\\\n```\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/tools.py#L39)\\\\n\\\\n### sed\\\\n\\\\n>\\\\n```\\\\n>      sed (argstr:str, disallow_re:str=None, allow_re:str=None)\\\\n```\\\\n\\\\n_Run the[`sed`](https://fastcore.fast.ai/tools.html#sed) command with the args in `argstr` (e.g for reading a section of a file)_\\\\n\\\\n| **Type** | **Default** | **Details**  \\\\n---|---|---|---  \\\\nargstr | str |  | All args to the command, will be split with shlex  \\\\ndisallow_re | str | None | optional regex which, if matched on argstr, will disallow the command  \\\\nallow_re | str | None | optional regex which, if not matched on argstr, will disallow the command\\\\n```\\\\nprint(sed(\\\\'-n \\\"1,5 p\\\" _quarto.yml\\\\'))\\\\n```  \\\\n  \\\\n__\\\\n\\\\n```\\\\nproject:\\\\n  type: website\\\\n  pre-render: \\\\n    - pysym2md --output_file apilist.txt fastcore\\\\n  post-render: \\\\n\\\\n```\\\\n\\\\n```\\\\n# Print line numbers too\\\\nprint(sed(\\\\'-n \\\"1,5 {=;p;}\\\" _quarto.yml\\\\'))\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n1\\\\nproject:\\\\n2\\\\n  type: website\\\\n3\\\\n  pre-render: \\\\n4\\\\n    - pysym2md --output_file apilist.txt fastcore\\\\n5\\\\n  post-render: \\\\n\\\\n```\\\\n\\\\n## Text Edit Tools\\\\n\\\\nPython implementations of the text editor tools from [Anthropic](https://docs.claude.com/en/docs/agents-and-tools/tool-use/text-editor-tool). These tools are especially useful in an AI\\u2019s tool loop. See [`claudette`](https://claudette.answer.ai/text_editor.html) for examples.\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/tools.py#L48)\\\\n\\\\n### view\\\\n\\\\n>\\\\n```\\\\n>      view (path:str, view_range:tuple[int,int]=None, nums:bool=False)\\\\n```\\\\n\\\\n_View directory or file contents with optional line range and numbers_\\\\n\\\\n| **Type** | **Default** | **Details**  \\\\n---|---|---|---  \\\\npath | str |  | Path to directory or file to view  \\\\nview_range | tuple | None | Optional 1-indexed (start, end) line range for files, end=-1 for EOF  \\\\nnums | bool | False | Whether to show line numbers  \\\\n  \\\\nYou can specify line ranges and whether to have the output contain line numbers:\\\\n\\\\n```\\\\nprint(view(\\\\'_quarto.yml\\\\', (1,10), nums=True))\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\n 1 \\u2502 project:\\\\n 2 \\u2502   type: website\\\\n 3 \\u2502   pre-render: \\\\n 4 \\u2502     - pysym2md --output_file apilist.txt fastcore\\\\n 5 \\u2502   post-render: \\\\n 6 \\u2502     - llms_txt2ctx llms.txt --optional true --save_nbdev_fname llms-ctx-full.txt\\\\n 7 \\u2502     - llms_txt2ctx llms.txt --save_nbdev_fname llms-ctx.txt\\\\n 8 \\u2502   resources: \\\\n 9 \\u2502     - \\\"*.txt\\\"\\\\n10 \\u2502   preview:\\\\n```\\\\n\\\\nHere\\u2019s what the output looks like when viewing a directory:\\\\n\\\\n```\\\\nprint(view(\\\\'.\\\\', (1,5)))\\\\n```\\\\n\\\\n__\\\\n\\\\n```\\\\nDirectory contents of /Users/jhoward/aai-ws/fastcore/nbs:\\\\n/Users/jhoward/aai-ws/fastcore/nbs/llms.txt\\\\n/Users/jhoward/aai-ws/fastcore/nbs/000_tour.ipynb\\\\n/Users/jhoward/aai-ws/fastcore/nbs/parallel_test.py\\\\n/Users/jhoward/aai-ws/fastcore/nbs/_quarto.yml\\\\n/Users/jhoward/aai-ws/fastcore/nbs/08_style.ipynb\\\\n```\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/tools.py#L76)\\\\n\\\\n### create\\\\n\\\\n>\\\\n```\\\\n>      create (path:str, file_text:str, overwrite:bool=False)\\\\n```\\\\n\\\\n_Creates a new file with the given content at the specified path_\\\\n\\\\n| **Type** | **Default** | **Details**  \\\\n---|---|---|---  \\\\npath | str |  | Path where the new file should be created  \\\\nfile_text | str |  | Content to write to the file  \\\\noverwrite | bool | False | Whether to overwrite existing files  \\\\n**Returns** | **str** |  | \\\\n```\\\\nprint(create(\\\\'test.txt\\\\', \\\\'Hello, world!\\\\'))\\\\nf = Path(\\\\'test.txt\\\\')\\\\ntest_eq(f.exists(), True)\\\\nprint(\\\\'Contents:\\\\\\\\n\\\\', view(f, nums=True))\\\\n```  \\\\n  \\\\n__\\\\n\\\\n```\\\\nCreated file test.txt.\\\\nContents:\\\\n      1 \\u2502 Hello, world!\\\\n```\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/tools.py#L92)\\\\n\\\\n### insert\\\\n\\\\n>\\\\n```\\\\n>      insert (path:str, insert_line:int, new_str:str)\\\\n```\\\\n\\\\n_Insert new_str at specified line number_\\\\n\\\\n| **Type** | **Details**  \\\\n---|---|---  \\\\npath | str | Path to the file to modify  \\\\ninsert_line | int | Line number where to insert (0-based indexing)  \\\\nnew_str | str | Text to insert at the specified line  \\\\n**Returns** | **str** | \\\\n```\\\\ninsert(f, 0, \\\\'Let\\\\\\\\\\\\'s add a new line\\\\')\\\\nprint(view(f, nums=True))\\\\n```  \\\\n  \\\\n__\\\\n\\\\n```\\\\n1 \\u2502 Let\\\\'s add a new line\\\\n2 \\u2502 Hello, world!\\\\n```\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/tools.py#L110)\\\\n\\\\n### str_replace\\\\n\\\\n>\\\\n```\\\\n>      str_replace (path:str, old_str:str, new_str:str)\\\\n```\\\\n\\\\n_Replace first occurrence of old_str with new_str in file_\\\\n\\\\n| **Type** | **Details**  \\\\n---|---|---  \\\\npath | str | Path to the file to modify  \\\\nold_str | str | Text to find and replace  \\\\nnew_str | str | Text to replace with  \\\\n**Returns** | **str** | \\\\n```\\\\nstr_replace(f, \\\\'new line\\\\', \\\\'\\\\')\\\\nprint(view(f, nums=True))\\\\n```  \\\\n  \\\\n__\\\\n\\\\n```\\\\n1 \\u2502 Let\\\\'s add a \\\\n2 \\u2502 Hello, world!\\\\n```\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/tools.py#L129)\\\\n\\\\n### strs_replace\\\\n\\\\n>\\\\n```\\\\n>      strs_replace (path:str, old_strs:list[str], new_strs:list[str])\\\\n```\\\\n\\\\n_Replace for each str pair in old_strs,new_strs_\\\\n\\\\n| **Type** | **Details**  \\\\n---|---|---  \\\\npath | str | Path to the file to modify  \\\\nold_strs | list | List of strings to find and replace  \\\\nnew_strs | list | List of replacement strings (must match length of old_strs)\\\\n```\\\\nstrs_replace(f, [\\\"add a new line\\\", \\\"world!\\\"], [\\\"just say\\\", \\\"friends!\\\\\\\\nNice to see you.\\\"])\\\\nprint(view(f, nums=True))\\\\n```  \\\\n  \\\\n__\\\\n\\\\n```\\\\n1 \\u2502 Let\\\\'s add a \\\\n2 \\u2502 Hello, friends!\\\\n3 \\u2502 Nice to see you.\\\\n```\\\\n\\\\n* * *\\\\n\\\\n[source](https://github.com/AnswerDotAI/fastcore/blob/main/fastcore/tools.py#L139)\\\\n\\\\n### replace_lines\\\\n\\\\n>\\\\n```\\\\n>      replace_lines (path:str, start_line:int, end_line:int, new_content:str)\\\\n```\\\\n\\\\n_Replace lines in file using start and end line-numbers (index starting at 1)_\\\\n\\\\n| **Type** | **Details**  \\\\n---|---|---  \\\\npath | str | Path to the file to modify  \\\\nstart_line | int | Starting line number to replace (1-based indexing)  \\\\nend_line | int | Ending line number to replace (1-based indexing, inclusive)  \\\\nnew_content | str | New content to replace the specified lines\\\\n```\\\\nreplace_lines(\\\\'test.txt\\\\', 1, 2, \\\\'Replaced first two lines\\\\')\\\\nprint(view(\\\\'test.txt\\\\', nums=True))\\\\n```  \\\\n  \\\\n__\\\\n\\\\n```\\\\n1 \\u2502 Replaced first two lines\\\\n2 \\u2502 Nice to see you.\\\\n```\\\\n\\\\n```\\\\nf.unlink()\\\\n```\\\\n\\\\n__\\\\n\\\\n  * [__Report an issue](https://github.com/AnswerDotAI/fastcore/issues/new)'\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Good question! Looking at the fastcore documentation, `delegates` is actually in the `meta` module, not directly related to converting functions to JSON schemas for LLMs.\n",
    "\n",
    "For demonstrating what your function looks like to an LLM (i.e., generating a JSON schema), you'll want to look at a different approach. In the solveit environment, there's a helper function for this. Try:\n",
    "\n",
    "```python\n",
    "from claudette import toolloop\n",
    "import inspect\n",
    "```\n",
    "\n",
    "Then you can inspect your function and see how it would be represented as a tool schema. Would you like me to show you the specific code to generate the JSON schema for your `get_molecular_weight` function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3bde47",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "So. I don't think that is quite correct. Could you use web search to figure out how to demonstrate this? \n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! I found it. [*](https://amaarora.github.io/posts/2024-06-22%20Support%20bot.html \"Support bot with Claude 3.5 Sonnet using Claudette and Slack-SDK\") The function is called `get_schema` and it's from `toolslm.funccall`, not directly from `claudette`. Try this:\n",
    "\n",
    "```python\n",
    "from toolslm.funccall import get_schema\n",
    "get_schema(get_molecular_weight)\n",
    "```\n",
    "\n",
    "This should show you the JSON schema representation of your function that an LLM can understand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94008a94",
   "metadata": {
    "time_run": "1:16:34p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_molecular_weight',\n",
       " 'description': '\\n    Calculate the molecular weight of a molecule from its SMILES string.\\n\\n    Args:\\n        smiles: A SMILES string representing the molecule\\n\\n    Returns:\\n        The molecular weight in g/mol, or None if the SMILES is invalid\\n    \\n\\nReturns:\\n- type: number',\n",
       " 'input_schema': {'type': 'object',\n",
       "  'properties': {'smiles': {'type': 'string', 'description': ''}},\n",
       "  'required': ['smiles']}}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from toolslm.funccall import get_schema\n",
    "get_schema(get_molecular_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac158226",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "This is good, but that is the metadata description that is passed to the llm. How does a LLM actually 'invoke' a python function?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great question! The LLM doesn't directly invoke the Python function. Here's the flow:\n",
    "\n",
    "1. **LLM sees the schema** (what you just printed) and decides it needs to call the tool\n",
    "2. **LLM returns a tool call request** with the function name and arguments as JSON\n",
    "3. **Your code intercepts this** and actually executes the Python function\n",
    "4. **Results go back to the LLM** so it can continue reasoning\n",
    "\n",
    "Want to see this in action? We could demonstrate the complete loop where:\n",
    "- You give the LLM a task (e.g., \"What's the molecular weight of aspirin?\")\n",
    "- It decides to call `get_molecular_weight` \n",
    "- Your code executes it\n",
    "- The LLM uses the result to answer\n",
    "\n",
    "Should we build that demonstration next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f469a4",
   "metadata": {},
   "source": [
    "### Lookup SMILES string from Wikidata\n",
    "Wikidata [property https://www.wikidata.org/wiki/Property:P1687](https://www.wikidata.org/wiki/Property:P1687) for [SMILES https://www.wikidata.org/wiki/Q466769](https://www.wikidata.org/wiki/Q466769)   to lookup the SMILES string Wikidata. Note, [Isomemeric SMILES https://www.wikidata.org/wiki/Property:P2017](https://www.wikidata.org/wiki/Property:P2017). As an example [Ethanol https://www.wikidata.org/wiki/Q153](https://www.wikidata.org/wiki/Q153)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2a06c6",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Ok. I'm a bit worried you might hallucinate an SMILES String. Could we use Wikidata and the wikidata property for SMILES https://www.wikidata.org/wiki/Property:P1687 to lookup the SMILES string?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Good thinking! Using Wikidata will give us real, verified SMILES strings. \n",
    "\n",
    "To query Wikidata, we can use their SPARQL endpoint. Would you like to:\n",
    "\n",
    "1. Create a function that takes a molecule name (like \"caffeine\" or \"aspirin\") and returns its SMILES string from Wikidata?\n",
    "2. Or create a function that takes a Wikidata QID (like Q60235 for aspirin) and returns the SMILES?\n",
    "\n",
    "Which approach would work better for your demo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ddacee",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "No I want a function that queries the wikidata api given a chemical (ethanol) and returns the SMILES from wikidata.\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Got it! Here's a function that queries Wikidata's SPARQL endpoint to get the SMILES string for a chemical by name:\n",
    "\n",
    "```python\n",
    "import requests\n",
    "\n",
    "def get_smiles_from_wikidata(chemical_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the SMILES string for a chemical from Wikidata.\n",
    "    \n",
    "    Args:\n",
    "        chemical_name: The name of the chemical (e.g., \"ethanol\", \"caffeine\")\n",
    "        \n",
    "    Returns:\n",
    "        The SMILES string, or None if not found\n",
    "    \"\"\"\n",
    "    endpoint = \"https://query.wikidata.org/sparql\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT ?smiles WHERE {{\n",
    "      ?item rdfs:label \"{chemical_name}\"@en .\n",
    "      ?item wdt:P233 ?smiles .\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(endpoint, params={'query': query, 'format': 'json'})\n",
    "    data = response.json()\n",
    "    \n",
    "    if data['results']['bindings']:\n",
    "        return data['results']['bindings'][0]['smiles']['value']\n",
    "    return None\n",
    "```\n",
    "\n",
    "Go ahead and run this. Once it's defined, we can test it with \"ethanol\" and then show how both functions look to an LLM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158a5ac",
   "metadata": {
    "time_run": "5:42:31p"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_smiles_from_wikidata(chemical_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the SMILES string for a chemical from Wikidata.\n",
    "    \n",
    "    Args:\n",
    "        chemical_name: The name of the chemical (e.g., \"ethanol\", \"caffeine\")\n",
    "        \n",
    "    Returns:\n",
    "        The SMILES string, or None if not found\n",
    "    \"\"\"\n",
    "    endpoint = \"https://query.wikidata.org/sparql\"\n",
    "    \n",
    "    query = f\"\"\"\n",
    "    SELECT ?smiles WHERE {{\n",
    "      ?item rdfs:label \"{chemical_name}\"@en .\n",
    "      ?item wdt:P233 ?smiles .\n",
    "    }}\n",
    "    LIMIT 1\n",
    "    \"\"\"\n",
    "    \n",
    "    response = requests.get(endpoint, params={'query': query, 'format': 'json'})\n",
    "    data = response.json()\n",
    "    \n",
    "    if data['results']['bindings']:\n",
    "        return data['results']['bindings'][0]['smiles']['value']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b749a2d2",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Ok. How do I test this function?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Try calling it with a chemical name:\n",
    "\n",
    "```python\n",
    "get_smiles_from_wikidata(\"ethanol\")\n",
    "```\n",
    "\n",
    "This should return the SMILES string for ethanol. Give it a try!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b362ab18",
   "metadata": {
    "time_run": "5:42:31p"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CCO'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_smiles_from_wikidata(\"ethanol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e1f2f",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Ok. Can you demonstrate how to use &`get_molecular_weight` and &`get_smiles_from_wikidata`\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Perfect! Now that I have access to both tools via the ampersand-backtick notation, I can use them directly.\n",
    "\n",
    "Let me demonstrate by getting the molecular weight of ethanol:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01A2wbu9AZpXEAwse8D29Qk5\",\n",
    "  \"call\": {\n",
    "    \"function\": \"get_smiles_from_wikidata\",\n",
    "    \"arguments\": {\n",
    "      \"chemical_name\": \"ethanol\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'CCO'\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Now I'll use that SMILES string to calculate the molecular weight:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01DzKUxD8Gjrgby8SpXNUgiL\",\n",
    "  \"call\": {\n",
    "    \"function\": \"get_molecular_weight\",\n",
    "    \"arguments\": {\n",
    "      \"smiles\": \"CCO\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"46.069\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "So ethanol (CCO) has a molecular weight of approximately 46.07 g/mol!\n",
    "\n",
    "This demonstrates how an LLM can:\n",
    "1. Call the first tool to look up the SMILES string from Wikidata\n",
    "2. Use that result to call the second tool to calculate molecular weight\n",
    "3. Chain tools together to accomplish a task\n",
    "\n",
    "Would you like to try another chemical, or shall we look at how to inspect the JSON schema that describes these tools to the LLM?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c60931b",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "Could we try a harder example like semaglutide (Q27261089)?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "Great choice - semaglutide is a much more complex molecule (it's a peptide drug)! \n",
    "\n",
    "Let me try looking it up by name first:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01BNfTpowmE4y4PrZ4FGv7UW\",\n",
    "  \"call\": {\n",
    "    \"function\": \"get_smiles_from_wikidata\",\n",
    "    \"arguments\": {\n",
    "      \"chemical_name\": \"semaglutide\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"'CCC(C)C(NC(=O)C(Cc1ccccc1)NC(=O)C(CCC(=O)O)NC(=O)C(CCCCNC(=O)COCCOCCNC(=O)COCCOCCNC(=O)CCC(NC(=O)CCCCCCCCCCCCCCCCC(=O)O)C(=O)O)NC(=O)C(C)NC(=O)C(C)NC(=O)C(CCC(N)=O)NC(=O)CNC(=O)C(CCC(=O)O)NC(=O)C(CC(C)C)NC(=O)C(Cc1ccc(O)cc1)NC(=O)C(CO)NC(=O)C(CO)NC(=O)C(NC(=O)C(CC(=O)O)NC(=O)C(CO)NC(=O)C(NC(=O)C(Cc1ccccc1)NC(=O)C(NC(=O)CNC(=O)C(CCC(=O)O)NC(=O)C(C)(C)NC(=O)C(N)Cc1cnc[nH]1)C(C)O)C(C)O)C(C)C)C(=O)NC(C)C(=O)NC(Cc1c[nH]c2ccccc12)C(=O)NC(CC(C)C)C(=O)NC(C(=O)NC(CCCNC(=N)N)C(=O)NCC(=O)NC(CCCNC(=N)N)C(=O)NCC(=O)O)C(C)C'\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Wow, that's a huge SMILES string! Now let's calculate its molecular weight:\n",
    "\n",
    "<details class='tool-usage-details'>\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"toolu_01Kem9PMNQGLx12xnvVjMoL5\",\n",
    "  \"call\": {\n",
    "    \"function\": \"get_molecular_weight\",\n",
    "    \"arguments\": {\n",
    "      \"smiles\": \"CCC(C)C(NC(=O)C(Cc1ccccc1)NC(=O)C(CCC(=O)O)NC(=O)C(CCCCNC(=O)COCCOCCNC(=O)COCCOCCNC(=O)CCC(NC(=O)CCCCCCCCCCCCCCCCC(=O)O)C(=O)O)NC(=O)C(C)NC(=O)C(C)NC(=O)C(CCC(N)=O)NC(=O)CNC(=O)C(CCC(=O)O)NC(=O)C(CC(C)C)NC(=O)C(Cc1ccc(O)cc1)NC(=O)C(CO)NC(=O)C(CO)NC(=O)C(NC(=O)C(CC(=O)O)NC(=O)C(CO)NC(=O)C(NC(=O)C(Cc1ccccc1)NC(=O)C(NC(=O)CNC(=O)C(CCC(=O)O)NC(=O)C(C)(C)NC(=O)C(N)Cc1cnc[nH]1)C(C)O)C(C)O)C(C)C)C(=O)NC(C)C(=O)NC(Cc1c[nH]c2ccccc12)C(=O)NC(CC(C)C)C(=O)NC(C(=O)NC(CCCNC(=N)N)C(=O)NCC(=O)NC(CCCNC(=N)N)C(=O)NCC(=O)O)C(C)C\"\n",
    "    }\n",
    "  },\n",
    "  \"result\": \"4113.640999999982\"\n",
    "}\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "Excellent! Semaglutide has a molecular weight of approximately 4113.64 g/mol - that's a big molecule compared to ethanol's 46.07!\n",
    "\n",
    "This shows how the tools can handle both simple small molecules and complex peptides. What would you like to explore next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58fc105",
   "metadata": {
    "solveit_ai": true
   },
   "source": [
    "How could the \"inferred from smiles\" Wikidata Entity  https://www.wikidata.org/wiki/Q113907573 be used in this context for provenance annotation?\n",
    "\n",
    "##### 🤖Reply🤖<!-- SOLVEIT_SEPARATOR_7f3a9b2c -->\n",
    "\n",
    "That's a great question about provenance! The \"inferred from SMILES\" entity (Q113907573) is a Wikidata reference qualifier that indicates data was computationally derived from a SMILES string.\n",
    "\n",
    "In your context, you could use it to document that the molecular weight calculation was:\n",
    "1. Based on a SMILES string retrieved from Wikidata\n",
    "2. Computed (not experimentally measured)\n",
    "3. Traceable back to the original data source\n",
    "\n",
    "How would you want to capture this provenance? Some options:\n",
    "\n",
    "1. Return it as metadata alongside the molecular weight (e.g., as a dictionary with the value and provenance info)\n",
    "2. Log it separately for auditing purposes\n",
    "3. Structure it as RDF triples for semantic web applications\n",
    "\n",
    "What fits best with your use case for the CI infrastructure audience?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c0d3f5",
   "metadata": {},
   "source": [
    "### General Purpose Terminal Based Tools for Coding Agents\n",
    "\n",
    "- Somewhat based on the [\"Unix Philosophy\" https://en.wikipedia.org/wiki/Unix_philosophy](https://en.wikipedia.org/wiki/Unix_philosophy)\n",
    "- [Anthropic: \"Writing Effective tools for Agents With Agents\" https://www.anthropic.com/engineering/writing-tools-for-agents](https://www.anthropic.com/engineering/writing-tools-for-agents)\n",
    "\n",
    "Tools available from `fastcore.tools`:\n",
    "\n",
    "- &`rg`: Run the `rg` command with the args in `argstr` (no need to backslash escape)\n",
    "- &`sed`: Run the `sed` command with the args in `argstr` (e.g for reading a section of a file)\n",
    "- &`view`: View directory or file contents with optional line range and numbers\n",
    "- &`create`: Creates a new file with the given content at the specified path\n",
    "- &`insert`: Insert new_str at specified line number\n",
    "- &`str_replace`: Replace first occurrence of old_str with new_str in file\n",
    "- &`strs_replace`: Replace for each str pair in old_strs,new_strs\n",
    "- &`replace_lines`: Replace lines in file using start and end line-numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35a7f68",
   "metadata": {},
   "source": [
    "### Model Context Protocol (MCP) Standardized (Web)API for \"Tools\"\n",
    "\n",
    "- [\"What is Model Context Protocol?\" https://modelcontextprotocol.io/docs/getting-started/intro](https://modelcontextprotocol.io/docs/getting-started/intro)\n",
    "\n",
    "> \"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems.\n",
    "\n",
    ">Using MCP, AI applications like Claude or ChatGPT can connect to data sources (e.g. local files, databases), tools (e.g. search engines, calculators) and workflows (e.g. specialized prompts)—enabling them to access key information and perform tasks.\n",
    "\n",
    "> Think of MCP like a USB-C port for AI applications. Just as USB-C provides a standardized way to connect electronic devices, MCP provides a standardized way to connect AI applications to external systems.\"\n",
    "\n",
    "* Main mechanism for connecting Web API interfaces, Relational Databases and Documentation to LLM Agents\n",
    "* Claude, Claude Code, ChatGPT, Visual Studio Code support adding MCP servers as tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f311d9",
   "metadata": {},
   "source": [
    "## Agents and \"Agentic\" Workflows\n",
    "- [Sequoia AI Ascent event, \"What's next for AI agentic workflows ft. Andrew Ng of AI Fund\", https://youtu.be/sal78ACtGTc](https://youtu.be/sal78ACtGTc)\n",
    "- [Andrew Ng, \"The Batch\", Issue 253, June 12, 2024, https://www.deeplearning.ai/the-batch/issue-253/](https://www.deeplearning.ai/the-batch/issue-253/)\n",
    "\n",
    "> Rather than having to choose whether or not something is an agent in a binary way, I thought, it would be more useful to think of systems as being agent-like to different degrees. Unlike the noun “agent,” the adjective “agentic” allows us to contemplate such systems and include all of them in this growing movement.\n",
    "\n",
    "Andrew Ng Defined four \"Agentic Patterns\"\n",
    "- Reflection \n",
    "- Tool use\n",
    "- Planning\n",
    "- Multi-agent collaboration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7716a095",
   "metadata": {},
   "source": [
    "### However, this hasn't stopped the discussions on what is \"Agentic\"\n",
    "\n",
    "> \"An LLM agent runs tools in a loop to achieve a goal.\"\n",
    "\n",
    "- [I think “agent” may finally have a widely enough agreed upon definition to be useful jargon now](https://simonwillison.net/2025/Sep/18/agents/)\n",
    "\n",
    "![](./images/agentic.jpeg)\n",
    "- [Matt Pocock, X, https://x.com/mattpocockuk/status/1975655749251436738](https://x.com/mattpocockuk/status/1975655749251436738)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb00e108",
   "metadata": {},
   "source": [
    "### \"Vibe Coding\" and \"YOLO Mode\"\n",
    "\n",
    "Vibe Coding: [Mirriam-Webster](https://www.merriam-webster.com/slang/vibe-coding) and [Wikipedia](https://en.wikipedia.org/wiki/Vibe_coding) coined by Andrej Karpathy\n",
    "> \"Vibe coding (also written as vibecoding) is a recently-coined term for the practice of writing code, making web pages, or creating apps, by just telling an AI program what you want, and letting it create the product for you. In vibe coding the coder does not need to understand how or why the code works, and often will have to accept that a certain number of bugs and glitches will be present. The verb form of the word is vibe code.\"\n",
    "\n",
    "> \"YOLO mode,\" in the context of vibe coding, is an approach where a developer gives an autonomous AI agent complete control to execute tasks without requiring human permission. The name comes from the acronym YOLO (\"You Only Live Once\"), and it represents a high-risk, high-speed approach to AI-assisted development. \n",
    "\n",
    "- [Chika Ihejimba, PhD, \"Vibe Coding\", Apr 09, 2025,https://chikaihejimba.substack.com/p/vibe-coding](https://chikaihejimba.substack.com/p/vibe-coding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320416e8",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG)\n",
    "Imagine you’re building a giant language model (LLM) like ChatGPT. It’s been trained on lots of text, so it “knows” a lot of patterns. But two problems still bite you:\n",
    "\n",
    "- Memory / scale: The model’s internal weights can only capture so much. If you want up-to-date facts, niche documents, very large corpora, you can’t just cram all of that into the params.\n",
    "- Hallucination / accuracy: Pure generation means the model might “make things up” or approximate rather than fetch exact info.\n",
    "\n",
    "So the idea: let the model retrieve relevant documents / passages at inference time, then feed those as context into the LLM so it can generate an answer grounded in real retrieved material. That’s RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac6e86",
   "metadata": {},
   "source": [
    "### RAG pieces (modular breakdown)\n",
    "\n",
    "**The retrieval system:**\n",
    "- You have a large corpus (documents, web pages, knowledge-base).\n",
    "- Build an index (e.g., embedding index, vector store) so you can map a query → “top-k relevant documents”.\n",
    "- Techniques: embedding models (convert query + docs to vectors), nearest neighbour search (FAISS, Annoy, HNSW).\n",
    "- Example: embed each document d_i → v_i, embed query q → v_q, then find docs whose vectors v_i are near v_q (cosine similarity).\n",
    "- Output: a small set of snippets, passages, maybe full docs: D = \\{d_1, d_2, \\dots\\}.\n",
    "\n",
    "**The generation model (LLM):**\n",
    "- A transformer-based model trained for text generation (autoregressive, or sequence to sequence).\n",
    "- At inference, you concatenate or otherwise provide the retrieved docs + the user query (and maybe instructions) as input.\n",
    "- The LLM uses those docs as context to generate a response.\n",
    "\n",
    "**The glue / orchestration:**\n",
    "- You need to design how the docs are inserted into the prompt: inline, chunked, ranked, maybe with metadata (source, doc id).\n",
    "- You might filter/re-rank docs (only top 5, or only high quality).\n",
    "- You might decide how to prompt the model so it “uses” the docs (e.g., “Using the passages below, answer the question”, or “You are an expert, refer to the sources”).\n",
    "- You might include a source attribution mechanism (so answer can cite which doc it came from).\n",
    "\n",
    "<hr>\n",
    "\n",
    "- [I. Flath, \"Retrieval 101\",2025-03-17, https://isaacflath.com/blog/2025-03-17-Retrieval101](https://isaacflath.com/blog/2025-03-17-Retrieval101)\n",
    "- [I. Flath, \"Late Chunking: The Better Way to Embed Document Chunks\",2025-04-09,https://isaacflath.com/blog/2025-04-08-LateChunking](https://isaacflath.com/blog/2025-04-08-LateChunking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a5430d",
   "metadata": {},
   "source": [
    "### GraphRAG\n",
    "\n",
    "So, you already know **RAG (Retrieval-Augmented Generation)**.\n",
    "It solves “my LLM can’t remember the whole internet” by adding a retriever that fetches relevant chunks from a **vector database** — little islands of meaning.\n",
    "\n",
    "But here’s the problem:\n",
    "\n",
    "> “The world is not a pile of paragraphs. It’s a web of relationships.”\n",
    "\n",
    "Documents reference each other, entities co-occur, knowledge is relational.\n",
    "Plain RAG sees text as isolated chunks.\n",
    "GraphRAG connects them into a **knowledge graph** — a structure that encodes who is related to what and how.\n",
    "\n",
    "So instead of searching over disjoint vectors, we search and reason over a **graph topology**.\n",
    "\n",
    "🌐 GraphRAG Idea:\n",
    "\n",
    "- Represent knowledge as a **graph** (entities + relations).\n",
    "- Retrieval = **traversal**, not just vector search.\n",
    "- Feed connected **subgraphs** (not isolated chunks) to the LLM.\n",
    "\n",
    "<hr>\n",
    "\n",
    "- [Microsoft Research, \"GraphRAG: Unlocking LLM discovery on narrative private data\" (February 13, 2024), https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/](https://www.microsoft.com/en-us/research/blog/graphrag-unlocking-llm-discovery-on-narrative-private-data/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abbfff",
   "metadata": {},
   "source": [
    "### GraphRAG Example GraphRAG for Scientific Insight (Wikidata)**\n",
    "\n",
    "**Question (user query):**\n",
    "*“Which proteins interact with BRCA1 and are linked to breast cancer?”*\n",
    "\n",
    "**Why GraphRAG (intuition):**\n",
    "\n",
    "* RAG pulls **text chunks** → good facts, weak relationships\n",
    "* GraphRAG walks a **knowledge graph** (entities + relations) → multi-hop, explainable answers\n",
    "\n",
    "**We’ll click real nodes & relations:**\n",
    "\n",
    "* **BRCA1** (human tumor-suppressor) → [https://www.wikidata.org/wiki/Q227339](https://www.wikidata.org/wiki/Q227339) ([Wikidata][1])\n",
    "* **Breast cancer** → [https://www.wikidata.org/wiki/Q128581](https://www.wikidata.org/wiki/Q128581) ([Wikidata][2])\n",
    "* Property **“interacts with”** (`P129`) shown on BRCA1’s page (scroll to statements)\n",
    "* Property **“genetic association”** (`P2293`) definition → [https://www.wikidata.org/wiki/Property:P2293](https://www.wikidata.org/wiki/Property:P2293) ([Wikidata][3])\n",
    "\n",
    "**Example path you can inspect by clicking through BRCA1’s statements:**\n",
    "\n",
    "```\n",
    "BRCA1  --(interacts with/P129)-->  RAD51 family protein\n",
    "RAD51* --(genetic association/P2293)--> Breast cancer\n",
    "```\n",
    "\n",
    "Helpful RAD51 paralogs (human):\n",
    "\n",
    "* **RAD51C** → [https://www.wikidata.org/wiki/Q18031015](https://www.wikidata.org/wiki/Q18031015) ([Wikidata][4])\n",
    "* **RAD51B** → [https://www.wikidata.org/wiki/Q18031016](https://www.wikidata.org/wiki/Q18031016) ([Wikidata][5])\n",
    "\n",
    "> Tip: On the BRCA1 page, use the **“Statements”** section to find “interacts with,” click the target protein item, then look for disease associations on that protein’s page.\n",
    "\n",
    "** Generated entirely by ChatGPT using thinking, reflection and tool use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d1935",
   "metadata": {},
   "source": [
    "### GraphRAG Agentic Flow\n",
    "\n",
    "**1) Retrieve entry points (semantic search over labels/aliases):**\n",
    "Find BRCA1 and nearby nodes (proteins it *interacts with*) via their Wikidata pages.\n",
    "\n",
    "* BRCA1 → open statements → find **P129 (interacts with)** targets. ([Wikidata][1])\n",
    "\n",
    "**2) Expand neighborhood (graph traversal):**\n",
    "From those proteins (e.g., RAD51 family), follow **P2293 (genetic association)** to diseases (e.g., breast cancer).\n",
    "\n",
    "* P2293 docs → scope & meaning. ([Wikidata][3])\n",
    "* Breast cancer item for cross-check. ([Wikidata][2])\n",
    "\n",
    "**3) Serialize subgraph for the LLM (prompt context):**\n",
    "Minimal triples you can copy from the pages you clicked:\n",
    "\n",
    "```\n",
    "<BRCA1> --interacts with--> <RAD51C>\n",
    "<RAD51C> --genetic association--> <Breast cancer>\n",
    "```\n",
    "\n",
    "(You can substitute **RAD51B** similarly.) ([Wikidata][4])\n",
    "\n",
    "**4) Generate grounded answer (LLM prompt):**\n",
    "“Using these Wikidata facts (with Q-IDs/links), explain how BRCA1’s interaction partners connect to breast cancer and cite the items.”\n",
    "\n",
    "**TL;DR:**\n",
    "\n",
    "```\n",
    "LLM weights → baked patterns\n",
    "RAG        → fetch similar text\n",
    "GraphRAG   → walk the graph (entities/relations), then generate\n",
    "= Retrieval-Augmented Reasoning\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accc3996",
   "metadata": {},
   "source": [
    "## \"Prompt Engineering\" vs \"Context Engineering\"\n",
    "\n",
    "> \"Context refers to the set of tokens included when sampling from a large-language model (LLM). The engineering problem at hand is optimizing the utility of those tokens against the inherent constraints of LLMs in order to consistently achieve a desired outcome. Effectively wrangling LLMs often requires thinking in context — in other words: considering the holistic state available to the LLM at any given time and what potential behaviors that state might yield.\"\n",
    "\n",
    "![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Ffaa261102e46c7f090a2402a49000ffae18c5dd6-2292x1290.png&w=3840&q=75)\n",
    "---\n",
    "- [Anthropic Engineering, \"Effective context engineering for AI agents\", Sep 29, 2025, https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e72821",
   "metadata": {},
   "source": [
    "## FAIR Data in the Context of Generative AI\n",
    "\n",
    "[GoFAIR FAIR principles](https://www.go-fair.org/fair-principles/)\n",
    "- **F**indable\n",
    "- **A**ccessible\n",
    "- **I**nteroperable\n",
    "- **R**eusable\n",
    "\n",
    "> \"Humans, however, are not the only critical stakeholders in the milieu of scientific data. Similar problems are encountered by the applications and computational agents that we task to undertake data retrieval and analysis on our behalf. These ‘computational stakeholders’ are increasingly relevant, and demand as much, or more, attention as their importance grows. One of the grand challenges of data-intensive science, therefore, is to improve knowledge discovery through assisting both humans, and their computational agents, in the discovery of, access to, and integration and analysis of, task-appropriate scientific data and other scholarly digital objects.\"\n",
    "\n",
    ">\"It is for this reason that humans increasingly rely on computational agents to undertake discovery and integration tasks on their behalf. This necessitates machines to be capable of autonomously and appropriately acting when faced with the wide range of types, formats, and access-mechanisms/protocols that will be encountered during their **self-guided exploration** of the global data ecosystem. It also necessitates that the machines keep an exquisite **record of provenance** such that the data they are collecting can be accurately and adequately cited. Assisting these agents, therefore, is a critical consideration for all participants in the data management and stewardship process—from researchers and data producers to data repository hosts.\"\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "- [M. D. Wilkinson et al., “The FAIR Guiding Principles for scientific data management and stewardship,” Sci Data, vol. 3, p. 160018, Mar. 2016.https://www.nature.com/articles/sdata201618](https://www.nature.com/articles/sdata201618)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f7588",
   "metadata": {},
   "source": [
    "## FAIR Knowledge Graphs for the Sciences\n",
    "- [A. Waagmeester et al., “Wikidata as a knowledge graph for the life sciences,” Elife, vol. 9, Mar. 2020.https://pmc.ncbi.nlm.nih.gov/articles/PMC7077981/](https://pmc.ncbi.nlm.nih.gov/articles/PMC7077981/)\n",
    "- [C. Vardeman II, \"Wikidata Knowledge Graph for the Earth Sciences\",ESIP January 2022 Meeting, https://esip.figshare.com/articles/presentation/Wikidata_Knowledge_Graph_for_the_Earth_Sciences/19096856?file=33936803](https://esip.figshare.com/articles/presentation/Wikidata_Knowledge_Graph_for_the_Earth_Sciences/19096856?file=33936803)\n",
    "    - [Youtube: https://youtu.be/3oN67CfirDI](https://youtu.be/3oN67CfirDI)"
   ]
  }
 ],
 "metadata": {
  "solveit_dialog_mode": "learning",
  "solveit_ver": 2
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
